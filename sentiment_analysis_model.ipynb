{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVxuXeRe96I7a1LNezuOCN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5cd3872e870b4ec5a0be202a5cf94d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce186c5ab10a42bbb86258be177cb604",
              "IPY_MODEL_54112963bd854768941fa7ddebe25ecc",
              "IPY_MODEL_b3feeac64d554ae2bc0b5b97940cc0a2"
            ],
            "layout": "IPY_MODEL_e7d4e866c1ee40928ae2eef69f2a14f7"
          }
        },
        "ce186c5ab10a42bbb86258be177cb604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e459b689727d4489ad0782a16726f8b7",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc5cc259c7c41f4b969d56462398542",
            "value": "Map: 100%"
          }
        },
        "54112963bd854768941fa7ddebe25ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48cdc201cb0145e8b6a19d5d10f08e29",
            "max": 40000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29321e651eca4b8a841492c97980d103",
            "value": 40000
          }
        },
        "b3feeac64d554ae2bc0b5b97940cc0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212c89e5dd0b4236a0eccb6814cbfdcb",
            "placeholder": "​",
            "style": "IPY_MODEL_ee78a52280584697aa56a55582117b13",
            "value": " 40000/40000 [00:10&lt;00:00, 3722.54 examples/s]"
          }
        },
        "e7d4e866c1ee40928ae2eef69f2a14f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e459b689727d4489ad0782a16726f8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc5cc259c7c41f4b969d56462398542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48cdc201cb0145e8b6a19d5d10f08e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29321e651eca4b8a841492c97980d103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "212c89e5dd0b4236a0eccb6814cbfdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee78a52280584697aa56a55582117b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c942287af434a5cbbd8df9d04855515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59f621da72d04df486964323f44d58fc",
              "IPY_MODEL_1f6dc863c2d845fd875c278fc29daef2",
              "IPY_MODEL_fc36b025d39b4699b718248343112999"
            ],
            "layout": "IPY_MODEL_7dc2ae74b8e6477da07624f1eea8568f"
          }
        },
        "59f621da72d04df486964323f44d58fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_976bf8ccb9784d73b47d7ad2b50fec21",
            "placeholder": "​",
            "style": "IPY_MODEL_56f7d8b9662b4243bf85dddbe01bce00",
            "value": "Map: 100%"
          }
        },
        "1f6dc863c2d845fd875c278fc29daef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a8c3704108641f398a8d8804309b8ba",
            "max": 40000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce7ce98bdab74b5181e8a5c9214ffb84",
            "value": 40000
          }
        },
        "fc36b025d39b4699b718248343112999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee2528fade54600855537f75cf78a80",
            "placeholder": "​",
            "style": "IPY_MODEL_120ab4ec5caf49b2b8a6d544c0df4a5f",
            "value": " 40000/40000 [00:07&lt;00:00, 5359.58 examples/s]"
          }
        },
        "7dc2ae74b8e6477da07624f1eea8568f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "976bf8ccb9784d73b47d7ad2b50fec21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f7d8b9662b4243bf85dddbe01bce00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a8c3704108641f398a8d8804309b8ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce7ce98bdab74b5181e8a5c9214ffb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ee2528fade54600855537f75cf78a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120ab4ec5caf49b2b8a6d544c0df4a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f2e74ed000344adb82c70e9049210e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52fca9e8595747cfa2395ac9ee61ed19",
              "IPY_MODEL_787dd2d35fa04c4a9f831e5b474e4f3b",
              "IPY_MODEL_a766a6cb869c49a59ea05b214d97e022"
            ],
            "layout": "IPY_MODEL_5e1adb1ad8524a40aadbebc5dc545c69"
          }
        },
        "52fca9e8595747cfa2395ac9ee61ed19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ede0787a66740fd978c309f6535cfec",
            "placeholder": "​",
            "style": "IPY_MODEL_df2db95671d24c83a579f93a07e38a1a",
            "value": "Map: 100%"
          }
        },
        "787dd2d35fa04c4a9f831e5b474e4f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_948c4d54f7604809826d8753d36ec5bc",
            "max": 40000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b5c6494aa384070ad363f67a74abe5d",
            "value": 40000
          }
        },
        "a766a6cb869c49a59ea05b214d97e022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b86cae15294b4eaca8a19884a3e1d0de",
            "placeholder": "​",
            "style": "IPY_MODEL_fecf4925997a4cab83e592ed9add7109",
            "value": " 40000/40000 [00:09&lt;00:00, 5405.18 examples/s]"
          }
        },
        "5e1adb1ad8524a40aadbebc5dc545c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ede0787a66740fd978c309f6535cfec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2db95671d24c83a579f93a07e38a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "948c4d54f7604809826d8753d36ec5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b5c6494aa384070ad363f67a74abe5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b86cae15294b4eaca8a19884a3e1d0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fecf4925997a4cab83e592ed9add7109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurmugt/React-Todo-App/blob/main/sentiment_analysis_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f108879b"
      },
      "source": [
        "# Task\n",
        "Analyze the impact of text preprocessing and data augmentation on BERT model performance for tweet sentiment classification. This involves: loading the \"tweet_dataset.csv\" dataset; creating raw, cleaned, and augmented text versions; training three separate BERT models (Model A: raw text, Model B: cleaned text, Model C: augmented text); evaluating each model's performance using Accuracy, Precision, Recall, and F1-score; comparing the results in a table and visualization; and providing a detailed analysis and conclusion on the effectiveness of different preprocessing strategies in addressing the research gap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0496ea92"
      },
      "source": [
        "## Environment Setup and Library Imports\n",
        "\n",
        "### Subtask:\n",
        "Install and import all necessary libraries: transformers, torch, pandas, NumPy, scikit-learn, NLTK, emoji, and wordsegment. Also, download NLTK data like 'punkt' and 'wordnet' for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48c0c007",
        "outputId": "e8290c99-8a09-4be0-f004-09e93ef95ba5"
      },
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package_if_needed(package_for_pip):\n",
        "    \"\"\"Installs a pip package if it's not already present.\"\"\"\n",
        "    try:\n",
        "        # Check if the package is already installed by trying to list it\n",
        "        # This avoids issues with import names differing from pip package names.\n",
        "        subprocess.check_output([sys.executable, \"-m\", \"pip\", \"show\", package_for_pip])\n",
        "        print(f\"{package_for_pip} is already installed.\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"Installing {package_for_pip}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_for_pip])\n",
        "        print(f\"{package_for_pip} installed successfully.\")\n",
        "\n",
        "# Install libraries\n",
        "install_package_if_needed('transformers')\n",
        "install_package_if_needed('torch')\n",
        "install_package_if_needed('pandas')\n",
        "install_package_if_needed('numpy')\n",
        "install_package_if_needed('scikit-learn') # Pip install name\n",
        "install_package_if_needed('nltk')\n",
        "install_package_if_needed('emoji')\n",
        "install_package_if_needed('wordsegment')\n",
        "\n",
        "# Now import them explicitly using their standard import names\n",
        "import transformers\n",
        "import torch\n",
        "import pandas\n",
        "import numpy\n",
        "import sklearn # Correct import name for scikit-learn\n",
        "import nltk\n",
        "import emoji\n",
        "import wordsegment\n",
        "\n",
        "print(\"All required libraries are installed and imported.\")\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True) # Open Multilingual Wordnet for wordnet\n",
        "print(\"NLTK 'punkt' and 'wordnet' data downloaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers is already installed.\n",
            "torch is already installed.\n",
            "pandas is already installed.\n",
            "numpy is already installed.\n",
            "scikit-learn is already installed.\n",
            "nltk is already installed.\n",
            "Installing emoji...\n",
            "emoji installed successfully.\n",
            "Installing wordsegment...\n",
            "wordsegment installed successfully.\n",
            "All required libraries are installed and imported.\n",
            "NLTK 'punkt' and 'wordnet' data downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ae0199f"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the 'tweet_dataset.csv' file into a pandas DataFrame and inspect its structure, including column names and data types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8016bf0f"
      },
      "source": [
        "**Reasoning**:\n",
        "I will load the 'tweet_dataset.csv' file into a pandas DataFrame, display its first few rows, print its information to show column names and data types, and check for any missing values, all in a single code block to complete the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4d3b543",
        "outputId": "0bbf3a5d-c5e2-46f7-a49d-d6bb1ab558b9"
      },
      "source": [
        "df = pandas.read_csv('/content/tweet_dataset.csv')\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataFrame Info (column names and data types):\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "     tweet_id   sentiment                                            content\n",
            "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
            "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
            "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
            "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
            "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n",
            "\n",
            "DataFrame Info (column names and data types):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40000 entries, 0 to 39999\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   tweet_id   40000 non-null  int64 \n",
            " 1   sentiment  40000 non-null  object\n",
            " 2   content    40000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 937.6+ KB\n",
            "\n",
            "Missing values per column:\n",
            "tweet_id     0\n",
            "sentiment    0\n",
            "content      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60b72984"
      },
      "source": [
        "## Initial Data Preparation and Preprocessing Utilities\n",
        "\n",
        "### Subtask:\n",
        "Define utility functions for text cleaning and augmentation. This includes functions for lowercasing, removing URLs/mentions, converting emojis to text, splitting hashtags, normalizing slang (using a basic dictionary or placeholder), removing noise, and handling elongated words. Also, define functions for synonym replacement, random deletion, and random word swapping for augmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a900397",
        "outputId": "0a66ed5c-e428-43cc-c0a1-f31b8efb39bb"
      },
      "source": [
        "import re\n",
        "import random\n",
        "import emoji\n",
        "import wordsegment # Already installed/imported\n",
        "import nltk\n",
        "from nltk.corpus import wordnet, words\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download additional NLTK data if not already done (will be quiet if already present)\n",
        "nltk.download('words', quiet=True)\n",
        "\n",
        "# Ensure wordsegment data is loaded\n",
        "wordsegment.load()\n",
        "\n",
        "# Load English words for dictionary checks in handle_elongated_words\n",
        "english_words = set(words.words())\n",
        "\n",
        "def lowercase_text(text):\n",
        "    \"\"\"Converts input text to lowercase.\"\"\"\n",
        "    return text.lower()\n",
        "\n",
        "def remove_urls_mentions(text):\n",
        "    \"\"\"Removes URLs and Twitter mentions (@username) from the text.\"\"\"\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove mentions\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    return text\n",
        "\n",
        "def convert_emojis_to_text(text):\n",
        "    \"\"\"Replaces emojis with their textual descriptions (e.g., ':smile:').\"\"\"\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "def split_hashtags(text):\n",
        "    \"\"\"Uses wordsegment to split concatenated words in hashtags (e.g., '#LoveCoding' to 'Love Coding').\"\"\"\n",
        "    # Find hashtags\n",
        "    hashtags = re.findall(r'#(\\w+)', text)\n",
        "    for tag in hashtags:\n",
        "        # Segment the tag, then join with spaces\n",
        "        segmented_tag = ' '.join(wordsegment.segment(tag))\n",
        "        # Replace the original hashtag with the segmented version, removing the '#'\n",
        "        text = text.replace(f'#{tag}', segmented_tag)\n",
        "    return text\n",
        "\n",
        "def normalize_slang(text):\n",
        "    \"\"\"Replaces common slang words with their full forms using a basic dictionary, handling punctuation.\"\"\"\n",
        "    slang_map = {\n",
        "        'lol': 'laughing out loud',\n",
        "        'brb': 'be right back',\n",
        "        'np': 'no problem',\n",
        "        'gonna': 'going to',\n",
        "        'wanna': 'want to',\n",
        "        'u': 'you',\n",
        "        'r': 'are',\n",
        "        'btw': 'by the way',\n",
        "        'omg': 'oh my god',\n",
        "        'tho': 'though',\n",
        "        'ikr': 'i know right'\n",
        "    }\n",
        "    words_list = word_tokenize(text)\n",
        "    normalized_words = []\n",
        "    for word in words_list:\n",
        "        if word.lower() in slang_map:\n",
        "            normalized_words.append(slang_map[word.lower()])\n",
        "        else:\n",
        "            normalized_words.append(word)\n",
        "    return ' '.join(normalized_words)\n",
        "\n",
        "def remove_noise(text):\n",
        "    \"\"\"Removes special characters, punctuation (except for internal apostrophes), and excessive whitespace.\"\"\"\n",
        "    # Remove special characters and punctuation, but keep word-internal apostrophes and numbers\n",
        "    text = re.sub(r\"[^\\w\\s']|_\", '', text) # Keep alphanumeric, spaces, and apostrophes\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Replace multiple spaces with a single space and strip leading/trailing spaces\n",
        "    return text\n",
        "\n",
        "def handle_elongated_words(text):\n",
        "    \"\"\"Reduces repeated characters in elongated words (e.g., 'loooove' to 'love') while preserving dictionary words.\"\"\"\n",
        "    words_list = text.split()\n",
        "    processed_words = []\n",
        "    for word in words_list:\n",
        "        original_lower = word.lower()\n",
        "\n",
        "        # 1. If the word is already a valid English word, keep it as is.\n",
        "        if original_lower in english_words:\n",
        "            processed_words.append(word)\n",
        "            continue\n",
        "\n",
        "        # 2. Try an aggressive reduction (e.g., 'loooove' -> 'love', 'helllo' -> 'helo')\n",
        "        aggr_reduced = re.sub(r'(.)\\1+', r'\\1', word)\n",
        "        if aggr_reduced.lower() in english_words:\n",
        "            processed_words.append(aggr_reduced)\n",
        "            continue\n",
        "\n",
        "        # 3. Try a less aggressive reduction (e.g., 'loooove' -> 'loove', 'hellooo' -> 'helloo')\n",
        "        # This one only reduces repetitions of 3 or more characters to 2.\n",
        "        less_aggr_reduced = re.sub(r'(.)\\1{2,}', r'\\1\\1', word)\n",
        "        if less_aggr_reduced.lower() in english_words:\n",
        "            processed_words.append(less_aggr_reduced)\n",
        "            continue\n",
        "\n",
        "        # 4. If no dictionary word found through reduction,\n",
        "        #    and the word *was* elongated (had 3+ reps), use the less aggressive reduction as a default.\n",
        "        #    Otherwise, keep the original word (if it wasn't elongated).\n",
        "        if re.search(r'(.)\\1{2,}', word): # Check if the original word had 3 or more repetitions\n",
        "            processed_words.append(less_aggr_reduced) # Default for truly elongated words without dict match\n",
        "        else:\n",
        "            processed_words.append(word) # Keep original if not an elongated word or no reduction helps\n",
        "\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "def synonym_replacement(text, n=1):\n",
        "    \"\"\"Replaces a random word in the text with one of its synonyms using NLTK's WordNet.\"\"\"\n",
        "    words_list = word_tokenize(text)\n",
        "    new_words = words_list.copy()\n",
        "\n",
        "    # Consider only alphabetic words for replacement candidates\n",
        "    replacement_candidates = [word for word in words_list if word.isalpha() and word.lower() not in stopwords.words('english')]\n",
        "\n",
        "    if not replacement_candidates:\n",
        "        return text\n",
        "\n",
        "    # Perform 'n' replacements (or fewer if not enough unique candidates)\n",
        "    for _ in range(min(n, len(replacement_candidates))):\n",
        "        word_to_replace = random.choice(replacement_candidates)\n",
        "        replacement_candidates.remove(word_to_replace) # Avoid replacing the same word multiple times\n",
        "\n",
        "        synonyms = []\n",
        "        for syn in wordnet.synsets(word_to_replace):\n",
        "            for lemma in syn.lemmas():\n",
        "                synonym = lemma.name().replace('_', ' ')\n",
        "                if synonym.lower() != word_to_replace.lower(): # Ensure it's a different word\n",
        "                    synonyms.append(synonym)\n",
        "\n",
        "        if synonyms:\n",
        "            synonym_word = random.choice(synonyms)\n",
        "            # Replace the first occurrence of the word in new_words\n",
        "            try:\n",
        "                idx = new_words.index(word_to_replace)\n",
        "                new_words[idx] = synonym_word\n",
        "            except ValueError:\n",
        "                pass # Word not found, possibly due to prior replacement issues or punctuation\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def random_deletion(text, p=0.1):\n",
        "    \"\"\"Randomly deletes a word from the text with a given probability.\"\"\"\n",
        "    words_list = word_tokenize(text)\n",
        "    if len(words_list) == 0:\n",
        "        return text\n",
        "\n",
        "    new_words = []\n",
        "    for word in words_list:\n",
        "        r = random.uniform(0, 1)\n",
        "        if r > p:\n",
        "            new_words.append(word)\n",
        "\n",
        "    # If all words are deleted, return a random word from the original list to avoid empty string\n",
        "    if len(new_words) == 0:\n",
        "        return random.choice(words_list) if words_list else ''\n",
        "\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def random_swap(text, n=1):\n",
        "    \"\"\"Randomly swaps two words in the text for a specified number of times.\"\"\"\n",
        "    words_list = word_tokenize(text)\n",
        "    if len(words_list) < 2:\n",
        "        return text\n",
        "\n",
        "    new_words = words_list.copy()\n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(range(len(new_words)), 2)\n",
        "        new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
        "\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "print(\"All text preprocessing and augmentation utility functions are defined.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All text preprocessing and augmentation utility functions are defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83dc120c"
      },
      "source": [
        "## Create Raw Text Version\n",
        "\n",
        "### Subtask:\n",
        "Create a new column in the DataFrame that contains the original, raw text for Model A.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7aae4a9"
      },
      "source": [
        "**Reasoning**:\n",
        "To create the 'raw_text' column as requested, I will assign the 'content' column to a new column named 'raw_text' in the DataFrame `df`. After that, I will display the first few rows of the DataFrame to confirm the addition of the new column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a72bcac",
        "outputId": "95b51a82-09b0-4e83-d585-4e71631a57b7"
      },
      "source": [
        "df['raw_text'] = df['content']\n",
        "\n",
        "print(\"DataFrame with 'raw_text' column:\")\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with 'raw_text' column:\n",
            "     tweet_id   sentiment                                            content  \\\n",
            "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...   \n",
            "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...   \n",
            "2  1956967696     sadness                Funeral ceremony...gloomy friday...   \n",
            "3  1956967789  enthusiasm               wants to hang out with friends SOON!   \n",
            "4  1956968416     neutral  @dannycastillo We want to trade with someone w...   \n",
            "\n",
            "                                            raw_text  \n",
            "0  @tiffanylue i know  i was listenin to bad habi...  \n",
            "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
            "2                Funeral ceremony...gloomy friday...  \n",
            "3               wants to hang out with friends SOON!  \n",
            "4  @dannycastillo We want to trade with someone w...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9682b640"
      },
      "source": [
        "## Create Cleaned Text Version\n",
        "\n",
        "### Subtask:\n",
        "Apply the defined cleaning functions to the raw text to generate the 'cleaned_text' column for Model B.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32413774",
        "outputId": "83b2ed06-9ea6-4c3f-eaa2-aac133d22869"
      },
      "source": [
        "def apply_all_cleaning_functions(text):\n",
        "    \"\"\"Applies all defined cleaning functions in sequence.\"\"\"\n",
        "    text = lowercase_text(text)\n",
        "    text = remove_urls_mentions(text)\n",
        "    text = convert_emojis_to_text(text)\n",
        "    text = split_hashtags(text)\n",
        "    text = normalize_slang(text)\n",
        "    text = remove_noise(text)\n",
        "    text = handle_elongated_words(text)\n",
        "    return text\n",
        "\n",
        "# Apply the combined cleaning function to create 'cleaned_text'\n",
        "df['cleaned_text'] = df['raw_text'].apply(apply_all_cleaning_functions)\n",
        "\n",
        "print(\"DataFrame with 'raw_text' and 'cleaned_text' columns:\")\n",
        "print(df[['raw_text', 'cleaned_text']].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with 'raw_text' and 'cleaned_text' columns:\n",
            "                                            raw_text  \\\n",
            "0  @tiffanylue i know  i was listenin to bad habi...   \n",
            "1  Layin n bed with a headache  ughhhh...waitin o...   \n",
            "2                Funeral ceremony...gloomy friday...   \n",
            "3               wants to hang out with friends SOON!   \n",
            "4  @dannycastillo We want to trade with someone w...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  i know i was listenin to bad habit earlier and...  \n",
            "1  layin n bed with a headache ugh waitin on your...  \n",
            "2                     funeral ceremony gloomy friday  \n",
            "3                wants to hang out with friends soon  \n",
            "4  we want to trade with someone who has houston ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40dc7846"
      },
      "source": [
        "## Create Augmented Text Version\n",
        "\n",
        "### Subtask:\n",
        "Apply the defined augmentation techniques (synonym replacement, random deletion, random swap) to the original or cleaned text to create the 'augmented_text' column for Model C. This step will ensure we have sufficient data variations for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e8faa6e"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate the augmented text, I will define a function that applies the previously defined augmentation techniques sequentially to the 'cleaned_text' column, and then create a new 'augmented_text' column in the DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb42d041",
        "outputId": "93e932f1-23d2-4044-8118-23a4ee6a6717"
      },
      "source": [
        "def apply_augmentation_functions(text):\n",
        "    \"\"\"Applies a sequence of augmentation functions to the text.\"\"\"\n",
        "    # Ensure the text is not empty before applying augmentation\n",
        "    if not text.strip():\n",
        "        return text\n",
        "\n",
        "    # Apply synonym replacement\n",
        "    augmented_text = synonym_replacement(text, n=1)\n",
        "\n",
        "    # Apply random deletion (if text is not empty after synonym replacement)\n",
        "    if augmented_text.strip():\n",
        "        augmented_text = random_deletion(augmented_text, p=0.1)\n",
        "\n",
        "    # Apply random swap (if text has enough words after deletion)\n",
        "    if len(augmented_text.split()) >= 2:\n",
        "        augmented_text = random_swap(augmented_text, n=1)\n",
        "\n",
        "    return augmented_text\n",
        "\n",
        "# Apply the augmentation function to create 'augmented_text'\n",
        "# For demonstration, we will apply it to a sample of the cleaned text to save computational time\n",
        "# For full execution, df['cleaned_text'].apply(apply_augmentation_functions)\n",
        "\n",
        "# Note: Augmentation can be computationally intensive and significantly increase processing time for large datasets.\n",
        "# For the purpose of demonstration and to manage execution time, we will apply augmentation to a subset\n",
        "# or consider applying it only to the training set later, if performance becomes an issue.\n",
        "# For this step, we will apply it directly to the cleaned_text column to fulfill the subtask requirement.\n",
        "\n",
        "df['augmented_text'] = df['cleaned_text'].apply(apply_augmentation_functions)\n",
        "\n",
        "print(\"DataFrame with 'raw_text', 'cleaned_text', and 'augmented_text' columns (first 5 rows):\")\n",
        "print(df[['raw_text', 'cleaned_text', 'augmented_text']].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with 'raw_text', 'cleaned_text', and 'augmented_text' columns (first 5 rows):\n",
            "                                            raw_text  \\\n",
            "0  @tiffanylue i know  i was listenin to bad habi...   \n",
            "1  Layin n bed with a headache  ughhhh...waitin o...   \n",
            "2                Funeral ceremony...gloomy friday...   \n",
            "3               wants to hang out with friends SOON!   \n",
            "4  @dannycastillo We want to trade with someone w...   \n",
            "\n",
            "                                        cleaned_text  \\\n",
            "0  i know i was listenin to bad habit earlier and...   \n",
            "1  layin n bed with a headache ugh waitin on your...   \n",
            "2                     funeral ceremony gloomy friday   \n",
            "3                wants to hang out with friends soon   \n",
            "4  we want to trade with someone who has houston ...   \n",
            "\n",
            "                                      augmented_text  \n",
            "0  i know i was listenin to bad drug earlier part...  \n",
            "1      layin bed with vexation a waitin on your call  \n",
            "2                          observance funeral gloomy  \n",
            "3                  to wants advert with friends soon  \n",
            "4  we want to trade with someone who has Samuel t...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7aa714d"
      },
      "source": [
        "## Tokenization and Dataset Preparation\n",
        "\n",
        "### Subtask:\n",
        "Initialize the `bert-base-uncased` tokenizer. Tokenize the 'raw_text', 'cleaned_text', and 'augmented_text' columns. Prepare the tokenized data into suitable formats (e.g., HuggingFace datasets or PyTorch datasets) for training BERT models, including creating train/test splits for each version.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad1bb3d5"
      },
      "source": [
        "**Reasoning**:\n",
        "To address the subtask, I will initialize the BERT tokenizer, create a mapping for sentiment labels to numerical IDs, define a tokenization function that handles text and labels, convert the pandas DataFrame into a HuggingFace Dataset, apply the tokenization function to the raw, cleaned, and augmented text columns, and finally create train-test splits for each of the three resulting tokenized datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "5cd3872e870b4ec5a0be202a5cf94d74",
            "ce186c5ab10a42bbb86258be177cb604",
            "54112963bd854768941fa7ddebe25ecc",
            "b3feeac64d554ae2bc0b5b97940cc0a2",
            "e7d4e866c1ee40928ae2eef69f2a14f7",
            "e459b689727d4489ad0782a16726f8b7",
            "2cc5cc259c7c41f4b969d56462398542",
            "48cdc201cb0145e8b6a19d5d10f08e29",
            "29321e651eca4b8a841492c97980d103",
            "212c89e5dd0b4236a0eccb6814cbfdcb",
            "ee78a52280584697aa56a55582117b13",
            "2c942287af434a5cbbd8df9d04855515",
            "59f621da72d04df486964323f44d58fc",
            "1f6dc863c2d845fd875c278fc29daef2",
            "fc36b025d39b4699b718248343112999",
            "7dc2ae74b8e6477da07624f1eea8568f",
            "976bf8ccb9784d73b47d7ad2b50fec21",
            "56f7d8b9662b4243bf85dddbe01bce00",
            "9a8c3704108641f398a8d8804309b8ba",
            "ce7ce98bdab74b5181e8a5c9214ffb84",
            "3ee2528fade54600855537f75cf78a80",
            "120ab4ec5caf49b2b8a6d544c0df4a5f",
            "5f2e74ed000344adb82c70e9049210e9",
            "52fca9e8595747cfa2395ac9ee61ed19",
            "787dd2d35fa04c4a9f831e5b474e4f3b",
            "a766a6cb869c49a59ea05b214d97e022",
            "5e1adb1ad8524a40aadbebc5dc545c69",
            "6ede0787a66740fd978c309f6535cfec",
            "df2db95671d24c83a579f93a07e38a1a",
            "948c4d54f7604809826d8753d36ec5bc",
            "5b5c6494aa384070ad363f67a74abe5d",
            "b86cae15294b4eaca8a19884a3e1d0de",
            "fecf4925997a4cab83e592ed9add7109"
          ]
        },
        "id": "4268ded3",
        "outputId": "42021cad-025d-4522-a589-e31ecabd41a3"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Initialize BertTokenizerFast\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "print(\"BERT Tokenizer initialized.\")\n",
        "\n",
        "# 2. Create a dictionary mapping sentiment labels to numerical IDs\n",
        "unique_sentiments = df['sentiment'].unique()\n",
        "label_to_id = {label: i for i, label in enumerate(unique_sentiments)}\n",
        "id_to_label = {i: label for label, i in label_to_id.items()}\n",
        "num_labels = len(unique_sentiments)\n",
        "\n",
        "print(f\"Sentiment labels mapped to IDs: {label_to_id}\")\n",
        "\n",
        "# 3. Define a tokenization function\n",
        "def tokenize_function(examples):\n",
        "    # Tokenize the text\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['text'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=128, # A common max length for BERT for efficiency\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # Map sentiment labels to numerical IDs\n",
        "    tokenized_inputs['labels'] = [label_to_id[label] for label in examples['sentiment']]\n",
        "    return tokenized_inputs\n",
        "\n",
        "# 4. Convert DataFrame to HuggingFace Dataset and apply tokenization\n",
        "# First, create a HuggingFace Dataset from the pandas DataFrame\n",
        "hf_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Tokenize 'raw_text'\n",
        "raw_text_dataset = hf_dataset.map(\n",
        "    lambda examples: tokenize_function({'text': examples['raw_text'], 'sentiment': examples['sentiment']}),\n",
        "    batched=True,\n",
        "    remove_columns=['tweet_id', 'sentiment', 'content', 'raw_text', 'cleaned_text', 'augmented_text'] # Removed '__index_level_0__'\n",
        ")\n",
        "print(\"Raw text tokenization complete.\")\n",
        "\n",
        "# Tokenize 'cleaned_text'\n",
        "cleaned_text_dataset = hf_dataset.map(\n",
        "    lambda examples: tokenize_function({'text': examples['cleaned_text'], 'sentiment': examples['sentiment']}),\n",
        "    batched=True,\n",
        "    remove_columns=['tweet_id', 'sentiment', 'content', 'raw_text', 'cleaned_text', 'augmented_text'] # Removed '__index_level_0__'\n",
        ")\n",
        "print(\"Cleaned text tokenization complete.\")\n",
        "\n",
        "# Tokenize 'augmented_text'\n",
        "augmented_text_dataset = hf_dataset.map(\n",
        "    lambda examples: tokenize_function({'text': examples['augmented_text'], 'sentiment': examples['sentiment']}),\n",
        "    batched=True,\n",
        "    remove_columns=['tweet_id', 'sentiment', 'content', 'raw_text', 'cleaned_text', 'augmented_text'] # Removed '__index_level_0__'\n",
        ")\n",
        "print(\"Augmented text tokenization complete.\")\n",
        "\n",
        "# 5. Create train-test splits for each dataset\n",
        "TRAIN_TEST_SPLIT_RATIO = 0.2 # 20% for testing\n",
        "RANDOM_STATE = 42 # For reproducibility\n",
        "\n",
        "raw_text_splits = raw_text_dataset.train_test_split(test_size=TRAIN_TEST_SPLIT_RATIO, seed=RANDOM_STATE)\n",
        "train_raw = raw_text_splits['train']\n",
        "test_raw = raw_text_splits['test']\n",
        "print(f\"Raw text splits created. Train size: {len(train_raw)}, Test size: {len(test_raw)}\")\n",
        "\n",
        "cleaned_text_splits = cleaned_text_dataset.train_test_split(test_size=TRAIN_TEST_SPLIT_RATIO, seed=RANDOM_STATE)\n",
        "train_cleaned = cleaned_text_splits['train']\n",
        "test_cleaned = cleaned_text_splits['test']\n",
        "print(f\"Cleaned text splits created. Train size: {len(train_cleaned)}, Test size: {len(test_cleaned)}\")\n",
        "\n",
        "augmented_text_splits = augmented_text_dataset.train_test_split(test_size=TRAIN_TEST_SPLIT_RATIO, seed=RANDOM_STATE)\n",
        "train_augmented = augmented_text_splits['train']\n",
        "test_augmented = augmented_text_splits['test']\n",
        "print(f\"Augmented text splits created. Train size: {len(train_augmented)}, Test size: {len(test_augmented)}\")\n",
        "\n",
        "print(\"All tokenization and dataset preparation steps completed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Tokenizer initialized.\n",
            "Sentiment labels mapped to IDs: {'empty': 0, 'sadness': 1, 'enthusiasm': 2, 'neutral': 3, 'worry': 4, 'surprise': 5, 'love': 6, 'fun': 7, 'hate': 8, 'happiness': 9, 'boredom': 10, 'relief': 11, 'anger': 12}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cd3872e870b4ec5a0be202a5cf94d74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text tokenization complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c942287af434a5cbbd8df9d04855515"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text tokenization complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f2e74ed000344adb82c70e9049210e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmented text tokenization complete.\n",
            "Raw text splits created. Train size: 32000, Test size: 8000\n",
            "Cleaned text splits created. Train size: 32000, Test size: 8000\n",
            "Augmented text splits created. Train size: 32000, Test size: 8000\n",
            "All tokenization and dataset preparation steps completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "978a56f3"
      },
      "source": [
        "## Train BERT Model A (Raw Text)\n",
        "\n",
        "### Subtask:\n",
        "Configure and train a BertForSequenceClassification model using the HuggingFace Trainer on the tokenized 'raw_text' dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "8f7eb639",
        "outputId": "5ed55cd7-945b-4dbe-cb80-99a4c94b342b"
      },
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# 1. Define compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    # Handle cases where there might be no true positive for certain classes\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted', zero_division=0)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "# 2. Load pre-trained BertForSequenceClassification model\n",
        "# Ensure num_labels is defined from previous steps (it is, as 'num_labels' in kernel state)\n",
        "model_raw_text = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "print(\"BertForSequenceClassification model for raw text loaded.\")\n",
        "\n",
        "# 3. Define TrainingArguments for Model A\n",
        "training_args_raw_text = TrainingArguments(\n",
        "    output_dir='./results_raw_text',           # output directory\n",
        "    num_train_epochs=3,                        # total number of training epochs\n",
        "    per_device_train_batch_size=16,            # batch size per device during training\n",
        "    per_device_eval_batch_size=16,             # batch size per device during evaluation\n",
        "    warmup_steps=500,                          # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,                         # strength of weight decay\n",
        "    logging_dir='./logs_raw_text',             # directory for storing logs\n",
        "    logging_steps=100,                         # log every X updates steps\n",
        "    eval_strategy='epoch',                     # Corrected argument name from evaluation_strategy to eval_strategy\n",
        "    save_strategy='epoch',                     # save checkpoint every `epoch`\n",
        "    load_best_model_at_end=True,               # load the best model when training ends\n",
        "    metric_for_best_model='f1',                # use f1 to select the best model\n",
        "    report_to='none'                           # Disable reporting to experiment trackers\n",
        ")\n",
        "\n",
        "# 4. Initialize Trainer for Model A\n",
        "trainer_raw_text = Trainer(\n",
        "    model=model_raw_text,                      # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args_raw_text,               # training arguments, defined above\n",
        "    train_dataset=train_raw,                   # training dataset\n",
        "    eval_dataset=test_raw,                     # evaluation dataset\n",
        "    tokenizer=tokenizer,                       # the tokenizer used\n",
        "    compute_metrics=compute_metrics            # the function to compute metrics\n",
        ")\n",
        "print(\"Trainer for raw text model initialized.\")\n",
        "\n",
        "# 5. Start training\n",
        "print(\"Starting training for Model A (Raw Text). This may take a while...\")\n",
        "training_results_raw_text = trainer_raw_text.train()\n",
        "print(\"Training for Model A (Raw Text) completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification model for raw text loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3479077657.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_raw_text = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer for raw text model initialized.\n",
            "Starting training for Model A (Raw Text). This may take a while...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6000/6000 36:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.780400</td>\n",
              "      <td>1.798445</td>\n",
              "      <td>0.389125</td>\n",
              "      <td>0.406166</td>\n",
              "      <td>0.389125</td>\n",
              "      <td>0.354173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.628100</td>\n",
              "      <td>1.803685</td>\n",
              "      <td>0.394750</td>\n",
              "      <td>0.371082</td>\n",
              "      <td>0.394750</td>\n",
              "      <td>0.372071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.222700</td>\n",
              "      <td>1.988567</td>\n",
              "      <td>0.378875</td>\n",
              "      <td>0.362074</td>\n",
              "      <td>0.378875</td>\n",
              "      <td>0.363944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for Model A (Raw Text) completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc038245"
      },
      "source": [
        "# Task\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        " (Raw Text)\n",
        "Load a pre-trained BertForSequenceClassification model from 'bert-base-uncased' with `num_labels` for Model B, define its TrainingArguments with `output_dir='./results_cleaned_text'` and `logging_dir='./logs_cleaned_text'`, and then initialize a HuggingFace Trainer for Model B using `train_cleaned` and `test_cleaned` datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00ba10ef"
      },
      "source": [
        "## Load pre-trained BertForSequenceClassification model for Model B\n",
        "\n",
        "### Subtask:\n",
        "Load a new BertForSequenceClassification model from 'bert-base-uncased' with the appropriate number of labels for sentiment classification. This ensures a fresh model instance for training with cleaned data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "692273a3"
      },
      "source": [
        "**Reasoning**:\n",
        "To load the pre-trained BERT model for cleaned text, I will use `BertForSequenceClassification.from_pretrained` and assign it to `model_cleaned_text`, using the already defined `num_labels` for the classifier head.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a483571",
        "outputId": "09437e9e-e628-4218-d111-f211e5b873d7"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load pre-trained BertForSequenceClassification model for Model B\n",
        "# Ensure num_labels is defined from previous steps (it is, as 'num_labels' in kernel state)\n",
        "model_cleaned_text = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "print(\"BertForSequenceClassification model for cleaned text loaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification model for cleaned text loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8012f325"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully loaded the BERT model for cleaned text. Now, I will define the `TrainingArguments` for Model B, specifying the output and logging directories, as well as other training parameters such as epochs, batch sizes, and evaluation strategy. This sets up the configuration for training the model on the cleaned data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0c24caf",
        "outputId": "e928eaac-13f7-443b-f31a-0d70dd4166a8"
      },
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Define TrainingArguments for Model B (cleaned text)\n",
        "training_args_cleaned_text = TrainingArguments(\n",
        "    output_dir='./results_cleaned_text',           # output directory\n",
        "    num_train_epochs=3,                        # total number of training epochs\n",
        "    per_device_train_batch_size=16,            # batch size per device during training\n",
        "    per_device_eval_batch_size=16,             # batch size per device during evaluation\n",
        "    warmup_steps=500,                          # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,                         # strength of weight decay\n",
        "    logging_dir='./logs_cleaned_text',             # directory for storing logs\n",
        "    logging_steps=100,                         # log every X updates steps\n",
        "    eval_strategy='epoch',                     # evaluate each epoch\n",
        "    save_strategy='epoch',                     # save checkpoint every `epoch`\n",
        "    load_best_model_at_end=True,               # load the best model when training ends\n",
        "    metric_for_best_model='f1',                # use f1 to select the best model\n",
        "    report_to='none'                           # Disable reporting to experiment trackers\n",
        ")\n",
        "\n",
        "print(\"TrainingArguments for cleaned text model defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainingArguments for cleaned text model defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0885a826"
      },
      "source": [
        "**Reasoning**:\n",
        "With the model and training arguments defined, the next step is to initialize the HuggingFace Trainer for Model B. This involves passing the `model_cleaned_text`, `training_args_cleaned_text`, `train_cleaned`, `test_cleaned` datasets, the `tokenizer`, and the `compute_metrics` function to the `Trainer`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "420eae64",
        "outputId": "10dce3d3-33f7-4f03-904c-e02929bdb148"
      },
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# Initialize Trainer for Model B (cleaned text)\n",
        "trainer_cleaned_text = Trainer(\n",
        "    model=model_cleaned_text,                      # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args_cleaned_text,               # training arguments, defined above\n",
        "    train_dataset=train_cleaned,                   # training dataset\n",
        "    eval_dataset=test_cleaned,                     # evaluation dataset\n",
        "    tokenizer=tokenizer,                       # the tokenizer used\n",
        "    compute_metrics=compute_metrics            # the function to compute metrics\n",
        ")\n",
        "print(\"Trainer for cleaned text model initialized.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-330149946.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_cleaned_text = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer for cleaned text model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df4128e0"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block resulted in a `FutureWarning` because the `tokenizer` argument in `Trainer` is deprecated. I need to update the `Trainer` initialization to use `processing_class=tokenizer` instead to align with future versions of the HuggingFace `transformers` library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b0a7333",
        "outputId": "e98ae99c-e23b-461c-dac3-4fc2a64c7956"
      },
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# Initialize Trainer for Model B (cleaned text)\n",
        "trainer_cleaned_text = Trainer(\n",
        "    model=model_cleaned_text,                      # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args_cleaned_text,               # training arguments, defined above\n",
        "    train_dataset=train_cleaned,                   # training dataset\n",
        "    eval_dataset=test_cleaned,                     # evaluation dataset\n",
        "    processing_class=tokenizer,                # Use processing_class instead of tokenizer\n",
        "    compute_metrics=compute_metrics            # the function to compute metrics\n",
        ")\n",
        "print(\"Trainer for cleaned text model initialized.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer for cleaned text model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17299922"
      },
      "source": [
        "## Start training for Model B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "a94bac04",
        "outputId": "005eef21-b125-4bbc-fe56-80d26480f0d8"
      },
      "source": [
        "# Start training for Model B\n",
        "print(\"Starting training for Model B (Cleaned Text). This may take a while...\")\n",
        "training_results_cleaned_text = trainer_cleaned_text.train()\n",
        "print(\"Training for Model B (Cleaned Text) completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for Model B (Cleaned Text). This may take a while...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6000/6000 36:20, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.796200</td>\n",
              "      <td>1.802852</td>\n",
              "      <td>0.391375</td>\n",
              "      <td>0.358243</td>\n",
              "      <td>0.391375</td>\n",
              "      <td>0.354965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.633800</td>\n",
              "      <td>1.820047</td>\n",
              "      <td>0.386125</td>\n",
              "      <td>0.361949</td>\n",
              "      <td>0.386125</td>\n",
              "      <td>0.362607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.240600</td>\n",
              "      <td>2.007904</td>\n",
              "      <td>0.375500</td>\n",
              "      <td>0.351952</td>\n",
              "      <td>0.375500</td>\n",
              "      <td>0.360741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for Model B (Cleaned Text) completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c792b567"
      },
      "source": [
        "# Task\n",
        "Configure and train a BertForSequenceClassification model using the HuggingFace Trainer on the tokenized 'augmented_text' dataset to assess the impact of data augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b26242c"
      },
      "source": [
        "## Train BERT Model C (Augmented Text)\n",
        "\n",
        "### Subtask:\n",
        "Configure and train a BertForSequenceClassification model using the HuggingFace Trainer on the tokenized 'augmented_text' dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6894ed8e"
      },
      "source": [
        "**Reasoning**:\n",
        "To train BERT Model C, I need to first load a pre-trained `BertForSequenceClassification` model, similar to what was done for Models A and B, making sure to set the `num_labels` correctly for the sentiment classification task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5da6545f",
        "outputId": "8234ac7e-fdc6-415a-81aa-05d68daf19be"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load pre-trained BertForSequenceClassification model for Model C\n",
        "# Ensure num_labels is defined from previous steps (it is, as 'num_labels' in kernel state)\n",
        "model_augmented_text = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "print(\"BertForSequenceClassification model for augmented text loaded.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification model for augmented text loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "327dd7cf"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully loaded the BERT model for augmented text. Now, I will define the `TrainingArguments` for Model C, specifying the output and logging directories, as well as other training parameters. Then, I will initialize the HuggingFace `Trainer` for Model C, and finally, start the training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "8ad15337",
        "outputId": "7164fa70-69e1-4967-a7ef-4d0188f7e90b"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# 2. Define TrainingArguments for Model C (augmented text)\n",
        "training_args_augmented_text = TrainingArguments(\n",
        "    output_dir='./results_augmented_text',           # output directory\n",
        "    num_train_epochs=3,                        # total number of training epochs\n",
        "    per_device_train_batch_size=16,            # batch size per device during training\n",
        "    per_device_eval_batch_size=16,             # batch size per device during evaluation\n",
        "    warmup_steps=500,                          # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,                         # strength of weight decay\n",
        "    logging_dir='./logs_augmented_text',             # directory for storing logs\n",
        "    logging_steps=100,                         # log every X updates steps\n",
        "    eval_strategy='epoch',                     # evaluate each epoch\n",
        "    save_strategy='epoch',                     # save checkpoint every `epoch`\n",
        "    load_best_model_at_end=True,               # load the best model when training ends\n",
        "    metric_for_best_model='f1',                # use f1 to select the best model\n",
        "    report_to='none'                           # Disable reporting to experiment trackers\n",
        ")\n",
        "print(\"TrainingArguments for augmented text model defined.\")\n",
        "\n",
        "# 3. Initialize Trainer for Model C (augmented text)\n",
        "trainer_augmented_text = Trainer(\n",
        "    model=model_augmented_text,                      # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args_augmented_text,               # training arguments, defined above\n",
        "    train_dataset=train_augmented,                   # training dataset\n",
        "    eval_dataset=test_augmented,                     # evaluation dataset\n",
        "    processing_class=tokenizer,                # Use processing_class instead of tokenizer\n",
        "    compute_metrics=compute_metrics            # the function to compute metrics\n",
        ")\n",
        "print(\"Trainer for augmented text model initialized.\")\n",
        "\n",
        "# 4. Start training for Model C\n",
        "print(\"Starting training for Model C (Augmented Text). This may take a while...\")\n",
        "training_results_augmented_text = trainer_augmented_text.train()\n",
        "print(\"Training for Model C (Augmented Text) completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainingArguments for augmented text model defined.\n",
            "Trainer for augmented text model initialized.\n",
            "Starting training for Model C (Augmented Text). This may take a while...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6000/6000 36:24, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.880000</td>\n",
              "      <td>1.895886</td>\n",
              "      <td>0.354875</td>\n",
              "      <td>0.350228</td>\n",
              "      <td>0.354875</td>\n",
              "      <td>0.312184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.733700</td>\n",
              "      <td>1.889794</td>\n",
              "      <td>0.360250</td>\n",
              "      <td>0.333433</td>\n",
              "      <td>0.360250</td>\n",
              "      <td>0.330328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.328700</td>\n",
              "      <td>2.098958</td>\n",
              "      <td>0.341625</td>\n",
              "      <td>0.315635</td>\n",
              "      <td>0.341625</td>\n",
              "      <td>0.325928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for Model C (Augmented Text) completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "641a5fa5"
      },
      "source": [
        "**Reasoning**:\n",
        "The training for Model C has been completed. The next step is to evaluate its performance on the test_augmented dataset using the defined compute_metrics function. This will provide the necessary metrics (Accuracy, Precision, Recall, and F1-score) to compare with the other models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "ad119585",
        "outputId": "4b3ff595-5982-4435-e1fd-ccfe20dd33e2"
      },
      "source": [
        "print(\"Evaluating Model C (Augmented Text)...\")\n",
        "eval_results_augmented_text = trainer_augmented_text.evaluate()\n",
        "print(\"Evaluation Results for Model C (Augmented Text):\")\n",
        "print(eval_results_augmented_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Model C (Augmented Text)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 00:56]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results for Model C (Augmented Text):\n",
            "{'eval_loss': 1.8897939920425415, 'eval_accuracy': 0.36025, 'eval_precision': 0.33343252640212495, 'eval_recall': 0.36025, 'eval_f1': 0.330327748049129, 'eval_runtime': 56.8202, 'eval_samples_per_second': 140.795, 'eval_steps_per_second': 8.8, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e04d927"
      },
      "source": [
        "## Evaluate All Models\n",
        "\n",
        "### Subtask:\n",
        "Evaluate Model A and Model B on their respective test sets, and store their performance metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45b7b652"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate Model A and Model B, I will call the `.evaluate()` method on their respective trainers, `trainer_raw_text` and `trainer_cleaned_text`, using their corresponding test datasets, `test_raw` and `test_cleaned`. The results will be stored and then printed to inspect their performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "af0a3c5d",
        "outputId": "a982049c-e144-4a29-b93a-09d5dbe412d6"
      },
      "source": [
        "print(\"Evaluating Model A (Raw Text)...\")\n",
        "eval_results_raw_text = trainer_raw_text.evaluate()\n",
        "print(\"Evaluation Results for Model A (Raw Text):\")\n",
        "print(eval_results_raw_text)\n",
        "\n",
        "print(\"\\nEvaluating Model B (Cleaned Text)...\")\n",
        "eval_results_cleaned_text = trainer_cleaned_text.evaluate()\n",
        "print(\"Evaluation Results for Model B (Cleaned Text):\")\n",
        "print(eval_results_cleaned_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Model A (Raw Text)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 00:56]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results for Model A (Raw Text):\n",
            "{'eval_loss': 1.803685188293457, 'eval_accuracy': 0.39475, 'eval_precision': 0.3710823755227745, 'eval_recall': 0.39475, 'eval_f1': 0.3720711303978814, 'eval_runtime': 57.0683, 'eval_samples_per_second': 140.183, 'eval_steps_per_second': 8.761, 'epoch': 3.0}\n",
            "\n",
            "Evaluating Model B (Cleaned Text)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 00:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results for Model B (Cleaned Text):\n",
            "{'eval_loss': 1.8200469017028809, 'eval_accuracy': 0.386125, 'eval_precision': 0.36194939772310936, 'eval_recall': 0.386125, 'eval_f1': 0.362606951902177, 'eval_runtime': 55.1139, 'eval_samples_per_second': 145.154, 'eval_steps_per_second': 9.072, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "895a7acb"
      },
      "source": [
        "## Comparison Table and Visualization\n",
        "\n",
        "### Subtask:\n",
        "Present the evaluation metrics (Accuracy, Precision, Recall, F1-score) for all three models in a clear comparison table. Optionally, generate a bar chart or similar visualization to highlight the performance differences, ensuring all plots have clear legends.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1a9842e"
      },
      "source": [
        "**Reasoning**:\n",
        "To compare the models, I will first extract the relevant evaluation metrics (Accuracy, Precision, Recall, F1-score) from the `eval_results_raw_text`, `eval_results_cleaned_text`, and `eval_results_augmented_text` dictionaries. I will then organize these metrics into a dictionary and create a Pandas DataFrame from it, which will serve as the comparison table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74c43bac",
        "outputId": "2c66d136-96c1-4d32-cecb-6146be1c4afd"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Extract metrics for each model\n",
        "metrics_data = {\n",
        "    'Model': ['Model A (Raw)', 'Model B (Cleaned)', 'Model C (Augmented)'],\n",
        "    'Accuracy': [\n",
        "        eval_results_raw_text['eval_accuracy'],\n",
        "        eval_results_cleaned_text['eval_accuracy'],\n",
        "        eval_results_augmented_text['eval_accuracy']\n",
        "    ],\n",
        "    'Precision': [\n",
        "        eval_results_raw_text['eval_precision'],\n",
        "        eval_results_cleaned_text['eval_precision'],\n",
        "        eval_results_augmented_text['eval_precision']\n",
        "    ],\n",
        "    'Recall': [\n",
        "        eval_results_raw_text['eval_recall'],\n",
        "        eval_results_cleaned_text['eval_recall'],\n",
        "        eval_results_augmented_text['eval_recall']\n",
        "    ],\n",
        "    'F1-score': [\n",
        "        eval_results_raw_text['eval_f1'],\n",
        "        eval_results_cleaned_text['eval_f1'],\n",
        "        eval_results_augmented_text['eval_f1']\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "comparison_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "print(\"Comparison Table of Model Performance:\")\n",
        "print(comparison_df.set_index('Model'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison Table of Model Performance:\n",
            "                     Accuracy  Precision    Recall  F1-score\n",
            "Model                                                       \n",
            "Model A (Raw)        0.394750   0.371082  0.394750  0.372071\n",
            "Model B (Cleaned)    0.386125   0.361949  0.386125  0.362607\n",
            "Model C (Augmented)  0.360250   0.333433  0.360250  0.330328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a98b6fd"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the comparison table is created, I will generate a bar chart to visualize the performance differences for Accuracy, Precision, Recall, and F1-score across the three models, ensuring clear labels, a title, and a legend.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "5dc6b544",
        "outputId": "3ed66ac3-34a3-4ead-b21e-5417c64078eb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Prepare data for plotting\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "models = comparison_df['Model'].tolist()\n",
        "\n",
        "x = np.arange(len(metrics))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Plot bars for each model\n",
        "rects1 = ax.bar(x - width, comparison_df.loc[0, metrics].values, width, label='Model A (Raw)')\n",
        "rects2 = ax.bar(x, comparison_df.loc[1, metrics].values, width, label='Model B (Cleaned)')\n",
        "rects3 = ax.bar(x + width, comparison_df.loc[2, metrics].values, width, label='Model C (Augmented)')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Comparison of Model Performance Across Different Preprocessing Strategies')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "ax.set_ylim(0, 0.5) # Set y-axis limit for better visualization of differences\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "print(\"Bar chart visualization of model performance completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAKyCAYAAAAEvm1SAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhFhJREFUeJzs3Xt8z/X///H7NjvZbMNscxibOc5xJuehkhGKiBwyc0hpqRRRH8doFJJyypmIRDqJSs4pcj6fMlQYYcPYbHv9/vDb++ttG9vM6826XS+XXer9fD1fr9fj9X6/Xq/3dvd6PV92hmEYAgAAAAAAAExkb+sCAAAAAAAA8N9DKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUADzk7OzsNGzbM1mXcs/nz56tChQpydHSUl5eXrctJJyYmRnZ2dpozZ0625127dq3s7Oy0du3aXK/rXnzwwQcqXbq0HBwcVL16dVuXgzwss+Nn5cqVql69ulxcXGRnZ6dLly5JevDPB3jwBQQEqFu3brYu4z+jcePGaty4sa3LAPAQIpQC8NA7duyYevfurdKlS8vFxUUeHh6qX7++PvroI127ds3W5SELDh48qG7duikoKEjTp0/Xp59+mmnfYcOGyc7OTvb29jp16lS66fHx8XJ1dZWdnZ2ioqLuZ9m5bs6cObKzs7P8uLi4qFy5coqKitLZs2dzdV0//vijBgwYoPr162v27Nl67733cnX5/2Xt27eXnZ2d3nrrLVuXct/cup/my5dPhQoVUmhoqF599VXt378/S8v4999/1b59e7m6umrSpEmaP3++3NzcsnU+sLX9+/dr2LBhiomJyVL/tPNX2k/+/PkVHBys//3vf4qPj7+/xcI0V65c0dChQ1W5cmW5ubmpcOHCql69ul599VX9888/ln4rVqy4b/+olJCQoGHDhj1w/xgCALfLZ+sCAOBefP/993r22Wfl7Oysrl27qnLlykpKStLGjRvVv39/7du374H+gyY3XLt2TfnyPdyn87Vr1yo1NVUfffSRypQpk6V5nJ2d9fnnn2vAgAFW7cuWLbsfJZpqxIgRCgwM1PXr17Vx40ZNmTJFK1as0N69e5U/f/5cWccvv/wie3t7zZw5U05OTrmyTNwMRb/99lsFBATo888/1+jRo2VnZ2frsu6LJ554Ql27dpVhGIqLi9OuXbs0d+5cTZ48WWPGjFG/fv0sfUuVKqVr167J0dHR0rZ161ZdvnxZ7777rpo0aWJpz8n5wFb279+v4cOHq3HjxgoICMjyfFOmTJG7u7uuXLmiH3/8UaNGjdIvv/yiTZs25dn9xWyHDh2Svb35//5+48YNNWzYUAcPHlRERIReeeUVXblyRfv27dPChQvVpk0bFStWTNLNUGrSpEn3JZhKSEjQ8OHDJcmUK5h+/PHH+74OAHnTw/1XDID/tOPHj+u5555TqVKl9Msvv6ho0aKWaS+//LKOHj2q77//3oYV3j+pqalKSkqSi4uLXFxcbF3OPYuNjZWkbN2m8+STT2YYSi1cuFAtWrTQ0qVLc7NEUzVv3lw1a9aUJPXs2VOFCxfW+PHj9fXXX6tjx473tOyEhATlz59fsbGxcnV1zbVAyjAMXb9+Xa6urrmyvIfV0qVLlZKSolmzZumxxx7T+vXr1ahRo1xZ9tWrV+Xm5pYry8oN5cqVU5cuXazaRo8erVatWumNN95QhQoV9OSTT0qS5cq/W2V23OfkfHA3D9p7165dO3l7e0uSXnzxRbVt21bLli3Tb7/9prp162Y4T9qxa4YH7f3KCWdnZ5usd/ny5dqxY4cWLFigTp06WU27fv26kpKScrTc5ORkpaamPrD/iPCg1gXgwcftewAeWu+//76uXLmimTNnWgVSacqUKaNXX33V8jo5OVnvvvuugoKC5OzsrICAAL399ttKTEy0mi8gIEAtW7bU2rVrVbNmTbm6uqpKlSqWS+CXLVumKlWqyMXFRaGhodqxY4fV/N26dZO7u7v+/PNPhYeHy83NTcWKFdOIESNkGIZV37Fjx6pevXoqXLiwXF1dFRoaqi+//DLdtqTdirZgwQJVqlRJzs7OWrlypWXarf/KevnyZb322msKCAiQs7OzfHx89MQTT2j79u1Wy1yyZIlCQ0Pl6uoqb29vdenSRX///XeG2/L333+rdevWcnd3V5EiRfTmm28qJSUlk0/G2uTJky01FytWTC+//LJl3Ji093vo0KGSpCJFimR5jKxOnTpp586dOnjwoKXtzJkz+uWXX9L9IZAmNjZWPXr0kK+vr1xcXFStWjXNnTs3Xb9Lly6pW7du8vT0lJeXlyIiIqxqvtXBgwfVrl07FSpUSC4uLqpZs6a++eabu9afHY899pikm0Fsms8++8zy+RUqVEjPPfdcutsZGzdurMqVK2vbtm1q2LCh8ufPr7ffflt2dnaaPXu2rl69armNKG2sn+weJ6tWrbIcJ9OmTbOMn/XFF19o+PDhKl68uAoUKKB27dopLi5OiYmJeu211+Tj4yN3d3dFRkamW/bs2bP12GOPycfHR87OzgoODtaUKVPSvS9pNWzcuFG1atWSi4uLSpcurXnz5qXre+nSJb3++uuW46JEiRLq2rWrzp8/b+mTmJiooUOHqkyZMnJ2dpa/v78GDBiQrr47WbBggZ544gk9+uijqlixohYsWJBhv4MHD6p9+/YqUqSIXF1dVb58eb3zzjuW6Wm3ee3fv1+dOnVSwYIF1aBBg2x9Rn/88YfCw8Pl7e0tV1dXBQYGqnv37lZ9Fi1apNDQUBUoUEAeHh6qUqWKPvrooyxv7+0KFy6sRYsWKV++fBo1apSl/fYxpRo3bqyIiAhJ0iOPPCI7Ozt169btrueDH374QWFhYXJzc1OBAgXUokUL7du3z6qGtPPWsWPH9OSTT6pAgQLq3LmzpJuB/oQJE1SpUiW5uLjI19dXvXv31sWLF62WkZV9a86cOXr22WclSY8++qjlWMrJ7VK3H+OZHbtS1vfTW783ypcvb/nOWr9+vVW/3NjXpJufTaNGjSz70iOPPKKFCxda9fn999/VrFkzeXp6Kn/+/GrUqJE2bdpk1Scr32FHjhxR27Zt5efnJxcXF5UoUULPPfec4uLiLH1uH1Mq7fboTZs2qV+/fipSpIjc3NzUpk0bnTt3zqqG1NRUDRs2TMWKFVP+/Pn16KOPav/+/Vkap+rYsWOSpPr166ebljbEgHRzP500aZIk69thpf87XsaOHasJEyZY3v/9+/crKSlJQ4YMUWhoqDw9PeXm5qawsDCtWbPGsp6YmBgVKVJEkjR8+HDLsm89lrL63bV79241atRIrq6uKlGihEaOHKnZs2fLzs7O6rbVjMaUyuq++tNPP6lBgwby8vKSu7u7ypcvb9nfAeR9XCkF4KH17bffqnTp0qpXr16W+vfs2VNz585Vu3bt9MYbb+j3339XdHS0Dhw4oK+++sqq79GjR9WpUyf17t1bXbp00dixY9WqVStNnTpVb7/9tvr06SNJio6OVvv27dPdJpCSkqJmzZqpTp06ev/997Vy5UoNHTpUycnJGjFihKXfRx99pKeeekqdO3dWUlKSFi1apGeffVbfffedWrRoYVXTL7/8oi+++EJRUVHy9vbO9FaRF198UV9++aWioqIUHBysf//9Vxs3btSBAwdUo0YNSTd/OY+MjNQjjzyi6OhonT17Vh999JE2bdqkHTt2WF2hkJKSovDwcNWuXVtjx47Vzz//rHHjxikoKEgvvfTSHd/zYcOGafjw4WrSpIleeuklHTp0SFOmTNHWrVu1adMmOTo6asKECZo3b56++uoryy0tVatWvevn2bBhQ5UoUUILFy60vKeLFy+Wu7t7uvdOunmbY+PGjXX06FFFRUUpMDBQS5YsUbdu3XTp0iVLgGkYhp5++mlt3LhRL774oipWrKivvvrK8gf0rfbt26f69eurePHiGjhwoNzc3PTFF1+odevWWrp0qdq0aXPX7ciKtD9yChcuLEkaNWqUBg8erPbt26tnz546d+6cPv74YzVs2DDd5/fvv/+qefPmeu6559SlSxf5+vqqZs2a+vTTT7VlyxbNmDFDkizHUXaOk0OHDqljx47q3bu3evXqpfLly1umRUdHy9XVVQMHDtTRo0f18ccfy9HRUfb29rp48aKGDRum3377TXPmzFFgYKCGDBlimXfKlCmqVKmSnnrqKeXLl0/ffvut+vTpo9TUVL388stWNRw9elTt2rVTjx49FBERoVmzZqlbt24KDQ1VpUqVJN0c3yUsLEwHDhxQ9+7dVaNGDZ0/f17ffPON/vrrL3l7eys1NVVPPfWUNm7cqBdeeEEVK1bUnj179OGHH+rw4cNavnz5XT+nf/75R2vWrLEEnR07dtSHH36oTz75xOoqgt27dyssLEyOjo564YUXFBAQoGPHjunbb7+1CnIk6dlnn1XZsmX13nvvWULtrHxGsbGxatq0qYoUKaKBAwfKy8tLMTExVre3/vTTT+rYsaMef/xxjRkzRpJ04MABbdq0ySrQz66SJUuqUaNGWrNmjeLj4y1/hN/qnXfeUfny5fXpp59ablcNCgpS69atMz0fzJ8/XxEREQoPD9eYMWOUkJCgKVOmqEGDBtqxY4fVOTE5OVnh4eFq0KCBxo4da7nCqHfv3pbzX9++fXX8+HF98skn2rFjh+WclOZu+1bDhg3Vt29fTZw4UW+//bYqVqwoSZb/Zsftx7iU8bGb3f103bp1Wrx4sfr27StnZ2dNnjxZzZo105YtW1S5cmWrvjnd16Sb3yndu3dXpUqVNGjQIHl5eWnHjh1auXKl5R8JfvnlFzVv3lyhoaEaOnSo7O3tLQH0hg0bVKtWLUl3/w5LSkpSeHi4EhMT9corr8jPz09///23vvvuO126dEmenp53fK9feeUVFSxYUEOHDlVMTIwmTJigqKgoLV682NJn0KBBev/999WqVSuFh4dr165dCg8P1/Xr1+/6WZYqVUqSNG/ePP3vf//L9HbM3r17659//tFPP/2k+fPnZ9hn9uzZun79ul544QU5OzurUKFCio+P14wZM9SxY0f16tVLly9f1syZMxUeHq4tW7aoevXqKlKkiKZMmaKXXnpJbdq00TPPPCNJlmMpq99df//9tyVwHTRokNzc3DRjxowsXYWW1X113759atmypapWraoRI0bI2dlZR48eTRdWAsjDDAB4CMXFxRmSjKeffjpL/Xfu3GlIMnr27GnV/uabbxqSjF9++cXSVqpUKUOS8euvv1raVq1aZUgyXF1djRMnTljap02bZkgy1qxZY2mLiIgwJBmvvPKKpS01NdVo0aKF4eTkZJw7d87SnpCQYFVPUlKSUblyZeOxxx6zapdk2NvbG/v27Uu3bZKMoUOHWl57enoaL7/8cqbvRVJSkuHj42NUrlzZuHbtmqX9u+++MyQZQ4YMSbctI0aMsFpGSEiIERoamuk6DMMwYmNjDScnJ6Np06ZGSkqKpf2TTz4xJBmzZs2ytA0dOtSQZPXeZObWvm+++aZRpkwZy7RHHnnEiIyMNAzj5vty6/swYcIEQ5Lx2WefWb0XdevWNdzd3Y34+HjDMAxj+fLlhiTj/ffft/RLTk42wsLCDEnG7NmzLe2PP/64UaVKFeP69euWttTUVKNevXpG2bJlLW1r1qxJt59kZPbs2YYk4+effzbOnTtnnDp1yli0aJFRuHBhw9XV1fjrr7+MmJgYw8HBwRg1apTVvHv27DHy5ctn1d6oUSNDkjF16tR064qIiDDc3Nys2nJynKxcudKqb9q2Vq5c2UhKSrK0d+zY0bCzszOaN29u1b9u3bpGqVKlrNpuPy4MwzDCw8ON0qVLW7Wl1bB+/XpLW2xsrOHs7Gy88cYblrYhQ4YYkoxly5alW25qaqphGIYxf/58w97e3tiwYYPV9KlTpxqSjE2bNqWb93Zjx441XF1dLfvS4cOHDUnGV199ZdWvYcOGRoECBazOJbfWYhj/t5937NjRqk9WP6OvvvrKkGRs3bo103pfffVVw8PDw0hOTr7rtt3u9uMro2VLMnbt2mUYhmEcP3483fGTtr/fXmNG54PLly8bXl5eRq9evaz6njlzxvD09LRqTztvDRw40Krvhg0bDEnGggULrNpXrlyZrj2r+9aSJUuydGzfvm2HDh0yzp07Zxw/ftyYNm2a4ezsbPj6+hpXr141DCPzYzc7+6kkQ5Lxxx9/WNpOnDhhuLi4GG3atElXU073tUuXLhkFChQwateubfWdYhj/t0+npqYaZcuWNcLDw63284SEBCMwMNB44oknLG13+w7bsWOHIclYsmRJpn0M4+ZnGBERYXmdtr81adLEqobXX3/dcHBwMC5dumQYxs19Kl++fEbr1q2tljds2DBDktUyM5KQkGCUL1/ekGSUKlXK6NatmzFz5kzj7Nmz6fq+/PLLRkZ/jqUdLx4eHkZsbKzVtOTkZCMxMdGq7eLFi4avr6/RvXt3S9u5c+fS/X6QJqvfXa+88ophZ2dn7Nixw9L277//GoUKFTIkGcePH7e0N2rUyGjUqJHldVb31Q8//DDL3/8A8iZu3wPwUEp7SlGBAgWy1H/FihWSZDXwriS98cYbkpRu7Kng4GCrcT1q164t6eYtFiVLlkzX/ueff6Zb561Pfku7jSIpKUk///yzpf3W8XcuXryouLg4hYWFpbvVTpIaNWqk4ODgu2zpzXFYfv/9d6sn/Nzqjz/+UGxsrPr06WM1xkuLFi1UoUKFDMfhevHFF61eh4WFZbjNt/r555+VlJSk1157zeoqsl69esnDwyNXxvvq1KmTjh49qq1bt1r+m9mteytWrJCfn5/VmEyOjo7q27evrly5onXr1ln65cuXz+oqMAcHB73yyitWy7tw4YJ++eUXtW/fXpcvX9b58+d1/vx5/fvvvwoPD9eRI0fS3Q6ZVU2aNFGRIkXk7++v5557Tu7u7vrqq69UvHhxLVu2TKmpqWrfvr1lnefPn5efn5/Kli1rdQuHdHNclcjIyCytN7vHSWBgoMLDwzNcVteuXa2uOqldu7YMw0h3+1jt2rV16tQpJScnW9puPS7i4uJ0/vx5NWrUSH/++afV7TnSzWM1LCzM8rpIkSIqX7681f65dOlSVatWLcMr19KuYliyZIkqVqyoChUqWL2vabdV3f6+ZmTBggVq0aKF5bxUtmxZhYaGWt3Cd+7cOa1fv17du3e3OpfcWsutbj/2svoZpV0t99133+nGjRsZ1uvl5aWrV6/qp59+uuu2ZZe7u7ukm7di5YaffvpJly5dUseOHa0+HwcHB9WuXTvDz+f2KzmXLFkiT09PPfHEE1bLCA0Nlbu7e7plZGXfyqny5curSJEiCgwMVO/evVWmTBl9//33VmNGZXTsZnc/rVu3rkJDQy2vS5YsqaefflqrVq1Kdwt2Tve1n376SZcvX9bAgQPTjRuWtk/v3LlTR44cUadOnfTvv/9a6r569aoef/xxrV+/XqmpqZLu/h2WdiXUqlWrlJCQkGGfO3nhhResjrWwsDClpKToxIkTkqTVq1crOTnZckV0mtu/AzLj6uqq33//Xf3795d08yqyHj16qGjRonrllVeydTtw27ZtLbfhpXFwcLBceZmamqoLFy4oOTlZNWvWzPB3h9tl57tr5cqVqlu3rqpXr26Zv1ChQpbbYe8kq/tq2rnq66+/tuwDAP5buH0PwEMp7XaQrP7Bc+LECdnb26d7kpOfn5+8vLwsv4ymuf2PxbRfgv39/TNsv308Ent7e5UuXdqqrVy5cpJkNQbDd999p5EjR2rnzp1Wv6hm9MdpYGBgptt3q/fff18RERHy9/dXaGionnzySXXt2tVST9q23nqrVZoKFSpo48aNVm0uLi7pfikuWLBgum2+XWbrcXJyUunSpdO95zkREhKiChUqaOHChfLy8pKfn5/lF96M6ilbtmy6pzGl3WqTVs+JEydUtGhRyx/VaW7fjqNHj8owDA0ePFiDBw/OcJ2xsbEqXrx4trdr0qRJKleunPLlyydfX1+VL1/eUveRI0dkGIbKli2b4by3BkGSVLx48SwPQJvd4+RO+2R2jqHU1FTFxcVZbl3atGmThg4dqs2bN6f7ozMuLs7q9pzb1yOl3z+PHTumtm3bZlqrdPN9PXDgQLp9PU3a4NuZOXDggHbs2KGuXbvq6NGjlvbGjRtr0qRJltvY0gKN22+dyszt73FWP6NGjRqpbdu2Gj58uD788EM1btxYrVu3VqdOnSy33vTp00dffPGFmjdvruLFi6tp06Zq3769mjVrlqXa7uTKlSuSsv4PB3dz5MgRScr0+L79FsF8+fKpRIkS6ZYRFxcnHx+fDJdx+2eclX0rp5YuXSoPDw85OjqqRIkSCgoKStcno2M3u/tpRueJcuXKKSEhQefOnZOfn5+lPaf7Wtqth3fap9M+v4xug04TFxenggUL3vU7LDAwUP369dP48eO1YMEChYWF6amnnlKXLl3ueuuelP5zLViwoKT/+x5P267bt7tQoUKWvnfj6emp999/X++//75OnDih1atXa+zYsfrkk0/k6empkSNHZmk5mZ1j586dq3HjxungwYNWoXNWfk/IznfXiRMnMhx4PytPxczqvtqhQwfNmDFDPXv21MCBA/X444/rmWeeUbt27Wzy9EQA5iOUAvBQ8vDwULFixbR3795szZfVR207ODhkq924bQDzrNiwYYOeeuopNWzYUJMnT1bRokXl6Oio2bNnpxscVlKWn2rWvn17hYWF6auvvtKPP/6oDz74QGPGjNGyZcvUvHnzbNeZ2TY/KDp16qQpU6aoQIEC6tChg2m/xKb9i+6bb76Z6dVCOX2cfa1atSxP38tovXZ2dvrhhx8y/GxuD9Ny8jS8rB4nd1p2To+hY8eO6fHHH1eFChU0fvx4+fv7y8nJSStWrNCHH36Y7l/Sc+uYTE1NVZUqVTR+/PgMp98ept3us88+kyS9/vrrev3119NNX7p0aZavWLtVZu/x3T4jOzs7ffnll/rtt9/07bffatWqVerevbvGjRun3377Te7u7vLx8dHOnTu1atUq/fDDD/rhhx80e/Zsde3aNcMHAGTH3r175eDgkOUw/W7SPvf58+dbBSlp8uWz/pXW2dk53bkgNTVVPj4+mQ4+n9EVKRnJyfn+dg0bNrQ8fS8zGX3297qfZnd9UtbPB3eS9vl98MEHVlfd3Crt3JWV77Bx48apW7du+vrrr/Xjjz+qb9++io6O1m+//ZYujLzd/fxcM1KqVCl1795dbdq0UenSpbVgwYIsh1IZfSafffaZunXrptatW6t///7y8fGRg4ODoqOjLQHhndzP767b15OVfdXV1VXr16/XmjVr9P3332vlypVavHixHnvsMf34448P/O8gAO4doRSAh1bLli316aefavPmzZk+QjtNqVKllJqaqiNHjlgNQnv27FldunTJMjBpbklNTdWff/5puTpKkg4fPixJlsF4ly5dKhcXF61atcpq0NDZs2ff8/qLFi2qPn36qE+fPoqNjVWNGjU0atQoNW/e3LKthw4dSnfVwaFDh3Ltvbh1PbdeNZaUlKTjx4+rSZMmubKeTp06aciQITp9+nSmg8Wm1bN7926lpqZa/bGa9vS+tHpLlSql1atX68qVK1YBz6FDh6yWl7ZNjo6OubYtWREUFCTDMBQYGGi1f+UGs4+TjHz77bdKTEzUN998Y3VFQ1Zun8tMUFDQXQPsoKAg7dq1S48//ni2/wg3DEMLFy7Uo48+mu6WH0l69913tWDBAkVGRlr2m+wG6mmy+xnVqVNHderU0ahRo7Rw4UJ17txZixYtUs+ePSXdvHKxVatWatWqlVJTU9WnTx9NmzZNgwcPzvEfpidPntS6detUt27dXLtSKu1KIh8fnxwfb0FBQfr5559Vv379HIW1GcmNwCY7srufpl2hdKvDhw8rf/78mV7Bkiar+1raZ7N3795M95m0Ph4eHln6/O70HZamSpUqqlKliv73v//p119/Vf369TV16tQsBz6ZSduuo0ePWoWq//777z1dJVewYMF056Kc7D9ffvmlSpcurWXLllnNn/bUyrstOzvfXaVKlbK68jNNRm23y86+am9vr8cff1yPP/64xo8fr/fee0/vvPOO1qxZY+r3KwDb4JpIAA+tAQMGyM3NTT179tTZs2fTTT927Jjl0eZPPvmkJGnChAlWfdL+BS+jp7Xdq08++cTy/4Zh6JNPPpGjo6Mef/xxSTf/tdbOzs5qXI+YmJgsPeUrMykpKenG3PHx8VGxYsUstwfWrFlTPj4+mjp1qtUtgz/88IMOHDiQa+9FkyZN5OTkpIkTJ1r9C/TMmTMVFxeXa+sJCgrShAkTFB0dbXl6U0aefPJJnTlzxuoJS8nJyfr444/l7u6uRo0aWfolJydrypQpln4pKSn6+OOPrZbn4+Ojxo0ba9q0aTp9+nS69d3+iPHc8swzz8jBwUHDhw9P9y/7hmHo33//zfGybXGc3C7tX8Vv3ba4uLh7Cmvbtm2rXbt2pXt64K3rad++vf7++29Nnz49XZ9r167p6tWrmS5/06ZNiomJUWRkpNq1a5fup0OHDlqzZo3++ecfFSlSRA0bNtSsWbN08uTJDGu5k6x+RhcvXky3vLQrVNKO+9v3FXt7e8vTubIz7s2tLly4oI4dOyolJUXvvPNOjpaRkfDwcHl4eOi9997LcIysrBxv7du3V0pKit59991005KTk3Xp0qVs1+Xm5iZJOZo3J7K7n27evNlqnKFTp07p66+/VtOmTe96BUpW97WmTZuqQIECio6OTvd0urR9MDQ0VEFBQRo7dqzl1s5bpX1+WfkOi4+PtxqDTroZUNnb2+d4v73V448/rnz58ll9B0jW3+l3smvXLp0/fz5d+4kTJ7R//36rW8Fzsv9kdI78/ffftXnzZqt+aeOT3b7s7Hx3hYeHa/Pmzdq5c6el7cKFC5lebXirrO6rFy5cSDf99nMVgLyNK6UAPLSCgoK0cOFCdejQQRUrVlTXrl1VuXJlJSUl6ddff9WSJUvUrVs3SVK1atUUERGhTz/9VJcuXVKjRo20ZcsWzZ07V61bt9ajjz6aq7W5uLho5cqVioiIUO3atfXDDz/o+++/19tvv2351+kWLVpo/PjxatasmTp16qTY2FhNmjRJZcqU0e7du3O03suXL6tEiRJq166dqlWrJnd3d/3888/aunWrxo0bJ+nmv46OGTNGkZGRatSokTp27KizZ8/qo48+UkBAQIa3HuVEkSJFNGjQIA0fPlzNmjXTU089pUOHDmny5Ml65JFH1KVLl1xZj6QsPb7+hRde0LRp09StWzdt27ZNAQEB+vLLL7Vp0yZNmDDBckVHq1atVL9+fQ0cOFAxMTEKDg7WsmXL0v2hJN0c+6lBgwaqUqWKevXqpdKlS+vs2bPavHmz/vrrL+3atSvXtjFNUFCQRo4cqUGDBikmJkatW7dWgQIFdPz4cX311Vd64YUX9Oabb+Zo2WYfJxlp2rSp5eqd3r1768qVK5o+fbp8fHwy/AMqK/r3768vv/xSzz77rLp3767Q0FBduHBB33zzjaZOnapq1arp+eef1xdffKEXX3xRa9asUf369ZWSkqKDBw/qiy++0KpVqzK9pXLBggVycHDINLR76qmn9M4772jRokXq16+fJk6cqAYNGqhGjRp64YUXFBgYqJiYGH3//fdWf/xlJKuf0dy5czV58mS1adNGQUFBunz5sqZPny4PDw9L2NCzZ09duHBBjz32mEqUKKETJ07o448/VvXq1a2ujMnM4cOH9dlnn8kwDMXHx2vXrl1asmSJrly5Yjm35RYPDw9NmTJFzz//vGrUqKHnnntORYoU0cmTJ/X999+rfv36dw0NGjVqpN69eys6Olo7d+5U06ZN5ejoqCNHjmjJkiX66KOP1K5du2zVVb16dTk4OGjMmDGKi4uTs7OzHnvssUzHrbpX2d1PK1eurPDwcPXt21fOzs6aPHmyJGn48OF3XVdW9zUPDw99+OGH6tmzpx555BF16tRJBQsW1K5du5SQkKC5c+fK3t5eM2bMUPPmzVWpUiVFRkaqePHi+vvvv7VmzRp5eHjo22+/zdJ32C+//KKoqCg9++yzKleunJKTkzV//nw5ODjcdey4rPD19dWrr76qcePG6amnnlKzZs20a9cu/fDDD/L29r7rVT8//fSThg4dqqeeekp16tSRu7u7/vzzT82aNUuJiYkaNmyYpW/aIPR9+/ZVeHi4HBwc9Nxzz91x+S1bttSyZcvUpk0btWjRQsePH9fUqVMVHBxsFfi5uroqODhYixcvVrly5VSoUCFVrlxZlStXzvJ314ABA/TZZ5/piSee0CuvvCI3NzfNmDFDJUuW1IULF+74XmR1Xx0xYoTWr1+vFi1aqFSpUoqNjdXkyZNVokQJNWjQ4G4fF4C8wMxH/QHA/XD48GGjV69eRkBAgOHk5GQUKFDAqF+/vvHxxx9bPe74xo0bxvDhw43AwEDD0dHR8Pf3NwYNGmTVxzBuPka6RYsW6dajDB6BnvbY5g8++MDSFhERYbi5uRnHjh0zmjZtauTPn9/w9fU1hg4daqSkpFjNP3PmTKNs2bKGs7OzUaFCBWP27NmWx3Pfbd23Tkt75HNiYqLRv39/o1q1akaBAgUMNzc3o1q1asbkyZPTzbd48WIjJCTEcHZ2NgoVKmR07tzZ+Ouvv6z6pG3L7TKqMTOffPKJUaFCBcPR0dHw9fU1XnrpJePixYsZLi8rj4TOat+M3rOzZ88akZGRhre3t+Hk5GRUqVLF6hH1af7991/j+eefNzw8PAxPT0/j+eeftzyG/Pb+x44dM7p27Wr4+fkZjo6ORvHixY2WLVsaX375paXPmjVrsvTY+LRHlm/duvWO/QzDMJYuXWo0aNDAcHNzM9zc3IwKFSoYL7/8snHo0CFLn0aNGhmVKlXKcP7MPtt7PU7StvX2x7Vntm0ZfZ7ffPONUbVqVcPFxcUICAgwxowZY8yaNSvdI8gzq+H2R5Mbxs3PNCoqyihevLjh5ORklChRwoiIiDDOnz9v6ZOUlGSMGTPGqFSpkuHs7GwULFjQCA0NNYYPH27ExcWlfxP//zyFCxc2wsLCMpyeJjAw0AgJCbG83rt3r9GmTRvDy8vLcHFxMcqXL28MHjz4ju9Lmqx8Rtu3bzc6duxolCxZ0nB2djZ8fHyMli1bGn/88Yelz5dffmk0bdrU8PHxMZycnIySJUsavXv3Nk6fPn3HbTGMm8dX2o+9vb3h5eVlhISEGK+++qqxb9++dP3TzpW3Hj/Z2SfSrFmzxggPDzc8PT0NFxcXIygoyOjWrZvVdmW2b6f59NNPjdDQUMPV1dUoUKCAUaVKFWPAgAHGP//8Y+mTnX1r+vTpRunSpQ0HB4e7HudZPX/d6djN6n6adg787LPPLN8zISEh6eq7130tzTfffGPUq1fPcHV1NTw8PIxatWoZn3/+uVWfHTt2GM8884xRuHBhw9nZ2ShVqpTRvn17Y/Xq1YZhZO077M8//zS6d+9uBAUFGS4uLkahQoWMRx991Pj555+t1lWqVCkjIiLC8jqz/S2j83NycrIxePBgw8/Pz3B1dTUee+wx48CBA0bhwoWNF198McPP5db6hgwZYtSpU8fw8fEx8uXLZxQpUsRo0aKF8csvv1j1TU5ONl555RWjSJEihp2dneV7NaPfLdKkpqYa7733nlGqVCnLZ/rdd98ZERERRqlSpaz6/vrrr0ZoaKjh5ORk9buCYWTtu8swbn5mYWFhhrOzs1GiRAkjOjramDhxoiHJOHPmjKVfRsdGVvbV1atXG08//bRRrFgxw8nJyShWrJjRsWNH4/Dhw3d8nwHkHXaGcZ9G9QOA/6hu3brpyy+/zPAWBQAAzGBnZ6eXX345y7ed4c4uXbqkggULauTIkbl6a+rD6LXXXtO0adN05coVBiIHcM8YUwoAAAAA/r9r166la0sbW6tx48bmFmNjt78X//77r+bPn68GDRoQSAHIFYwpBQAAAAD/3+LFizVnzhw9+eSTcnd318aNG/X555+radOmql+/vq3LM1XdunXVuHFjVaxYUWfPntXMmTMVHx+vwYMH27o0AHkEoRQAAAAA/H9Vq1ZVvnz59P777ys+Pt4y+PnIkSNtXZrpnnzySX355Zf69NNPZWdnpxo1amjmzJlq2LChrUsDkEc8EGNKTZo0SR988IHOnDmjatWq6eOPP870sd5z5sxRZGSkVZuzs3O6R9ACAAAAAADgwWXzMaUWL16sfv36aejQodq+fbuqVaum8PBwxcbGZjqPh4eHTp8+bfk5ceKEiRUDAAAAAADgXtk8lBo/frx69eqlyMhIBQcHa+rUqcqfP79mzZqV6Tx2dnby8/Oz/Pj6+ppYMQAAAAAAAO6VTceUSkpK0rZt2zRo0CBLm729vZo0aaLNmzdnOt+VK1dUqlQppaamqkaNGnrvvfdUqVKlDPsmJiYqMTHR8jo1NVUXLlxQ4cKFZWdnl3sbAwAAAAAAABmGocuXL6tYsWKyt8/8eiibhlLnz59XSkpKuiudfH19dfDgwQznKV++vGbNmqWqVasqLi5OY8eOVb169bRv3z6VKFEiXf/o6GgNHz78vtQPAAAAAACAjJ06dSrDrCbNQ/f0vbp166pu3bqW1/Xq1VPFihU1bdo0vfvuu+n6Dxo0SP369bO8jouLU8mSJXXq1Cl5eHiYUjMAAAAAAMB/RXx8vPz9/VWgQIE79rNpKOXt7S0HBwedPXvWqv3s2bPy8/PL0jIcHR0VEhKio0ePZjjd2dlZzs7O6do9PDwIpQAAAAAAAO6Tuw2bZNOBzp2cnBQaGqrVq1db2lJTU7V69Wqrq6HuJCUlRXv27FHRokXvV5kAAAAAAADIZTa/fa9fv36KiIhQzZo1VatWLU2YMEFXr15VZGSkJKlr164qXry4oqOjJUkjRoxQnTp1VKZMGV26dEkffPCBTpw4oZ49e9pyMwAAAAAAAJANNg+lOnTooHPnzmnIkCE6c+aMqlevrpUrV1oGPz958qTVSO0XL15Ur169dObMGRUsWFChoaH69ddfFRwcbKtNAAAAAAAAQDbZGYZh2LoIM8XHx8vT01NxcXGMKQUAAAAAuKOUlBTduHHD1mUADxRHR0c5ODhkOj2r2YvNr5QCAAAAAOBBYxiGzpw5o0uXLtm6FOCB5OXlJT8/v7sOZn4nhFIAAAAAANwmLZDy8fFR/vz57+kPbyAvMQxDCQkJio2NlaR7evAcoRQAAAAAALdISUmxBFKFCxe2dTnAA8fV1VWSFBsbKx8fnzveyncn9nfvAgAAAADAf0faGFL58+e3cSXAgyvt+LiXMdcIpQAAAAAAyAC37AGZy43jg1AKAAAAAAAApiOUAgAAAAAAWbZ27VrZ2dll68mEAQEBmjBhwn2p599//5WPj49iYmLuy/Kzqk6dOlq6dKlNa3jYMNA5AAAAAABZFDDwe1PXFzO6Rbb6d+vWTXPnzlXv3r01depUq2kvv/yyJk+erIiICM2ZMycXq8w9f/31l0qXLq1y5cpp7969WZpn1KhRevrppxUQECBJiomJUWBgoGV6wYIFVaVKFY0cOVJhYWH3o2xJ0v/+9z+9/vrratOmjeztuQYoK3iXAAAAAADIQ/z9/bVo0SJdu3bN0nb9+nUtXLhQJUuWtGFldzdnzhy1b99e8fHx+v333+/aPyEhQTNnzlSPHj3STfv55591+vRprV+/XsWKFVPLli119uzZ+1G2JKl58+a6fPmyfvjhh/u2jryGUAoAAAAAgDykRo0a8vf317Jlyyxty5YtU8mSJRUSEmLVNzExUX379pWPj49cXFzUoEEDbd261arPihUrVK5cObm6uurRRx/N8Da5jRs3KiwsTK6urvL391ffvn119erVbNVtGIZmz56t559/Xp06ddLMmTPvOs+KFSvk7OysOnXqpJtWuHBh+fn5qXLlynr77bfTBV3z589XzZo1VaBAAfn5+alTp06KjY21TK9Zs6bGjh1red26dWs5OjrqypUrkm5e1WVnZ6ejR49KkhwcHPTkk09q0aJF2dru/zJCKQAAAAAA8pju3btr9uzZltezZs1SZGRkun4DBgzQ0qVLNXfuXG3fvl1lypRReHi4Lly4IEk6deqUnnnmGbVq1Uo7d+5Uz549NXDgQKtlHDt2TM2aNVPbtm21e/duLV68WBs3blRUVFS2al6zZo0SEhLUpEkTdenSRYsWLbprsLVhwwaFhobesc+1a9c0b948SZKTk5Ol/caNG3r33Xe1a9cuLV++XDExMerWrZtleqNGjbR27VpJNwOzDRs2yMvLSxs3bpQkrVu3TsWLF1eZMmUs89SqVUsbNmzIzmb/pxFKAQAAAACQx3Tp0kUbN27UiRMndOLECW3atEldunSx6nP16lVNmTJFH3zwgZo3b67g4GBNnz5drq6ulquUpkyZoqCgII0bN07ly5dX586drYIbSYqOjlbnzp312muvqWzZsqpXr54mTpyoefPm6fr161mueebMmXruuefk4OCgypUrq3Tp0lqyZMkd5zlx4oSKFSuW4bR69erJ3d1dbm5uGjt2rEJDQ/X4449bpnfv3l3NmzdX6dKlVadOHU2cOFE//PCD5Uqoxo0ba+PGjUpJSdHu3bvl5OSkzp07W4KqtWvXqlGjRlbrLFasmE6dOqXU1NQsb/d/GaEUAAAAAAB5TJEiRdSiRQvNmTNHs2fPVosWLeTt7W3V59ixY7px44bq169vaXN0dFStWrV04MABSdKBAwdUu3Ztq/nq1q1r9XrXrl2aM2eO3N3dLT/h4eFKTU3V8ePHs1TvpUuXtGzZMqvgrEuXLne9he/atWtycXHJcNrixYu1Y8cOLV26VGXKlNGcOXPk6Ohomb5t2za1atVKJUuWVIECBSwB08mTJyVJYWFhunz5snbs2KF169apUaNGaty4sSWUWrdunRo3bmy1TldXV6WmpioxMTFL2/1fx9P3AAAAAADIg7p37265hW7SpEn3bT1XrlxR79691bdv33TTsjqw+sKFC3X9+nWrAMwwDKWmpurw4cMqV65chvN5e3vr4sWLGU7z9/dX2bJlVbZsWSUnJ6tNmzbau3evnJ2ddfXqVYWHhys8PFwLFixQkSJFdPLkSYWHhyspKUmS5OXlpWrVqmnt2rXavHmznnjiCTVs2FAdOnTQ4cOHdeTIkXRXSl24cEFubm5ydXXN0nb/13GlFAAAAAAAeVCzZs2UlJSkGzduKDw8PN30oKAgOTk5adOmTZa2GzduaOvWrQoODpYkVaxYUVu2bLGa77fffrN6XaNGDe3fv19lypRJ93PrGE53MnPmTL3xxhvauXOn5WfXrl0KCwvTrFmzMp0vJCRE+/fvv+vy27Vrp3z58mny5MmSpIMHD+rff//V6NGjFRYWpgoVKlgNcp6mUaNGWrNmjdavX6/GjRurUKFCqlixokaNGqWiRYumC8v27t2bbjB5ZI5QCgAAAACAPMjBwUEHDhzQ/v375eDgkG66m5ubXnrpJfXv318rV67U/v371atXLyUkJKhHjx6SpBdffFFHjhxR//79dejQIS1cuFBz5syxWs5bb72lX3/9VVFRUdq5c6eOHDmir7/+OssDne/cuVPbt29Xz549VblyZaufjh07au7cuUpOTs5w3vDwcO3bty/Tq6XS2NnZqW/fvho9erQSEhJUsmRJOTk56eOPP9aff/6pb775Ru+++266+Ro3bqxVq1YpX758qlChgqVtwYIF6a6Skm4OvN60adMsbTcIpQAAAAAAyLM8PDzk4eGR6fTRo0erbdu2ev7551WjRg0dPXpUq1atUsGCBSXdvP1u6dKlWr58uapVq6apU6fqvffes1pG1apVtW7dOh0+fFhhYWEKCQnRkCFDMh2A/HYzZ85UcHCwJfS5VZs2bRQbG6sVK1ZkOG+VKlVUo0YNffHFF3ddT0REhG7cuKFPPvlERYoU0Zw5c7RkyRIFBwdr9OjRGjt2bLp5wsLClJqaahVANW7cWCkpKenGk/r777/166+/ZviUQ2TMzjAMw9ZFmCk+Pl6enp6Ki4u744EJAAAAAPhvun79uo4fP67AwMBMB9HGg+P7779X//79tXfvXtnb2+7am7feeksXL17Up59+arMazHSn4ySr2QsDnQMAAAAAgIdWixYtdOTIEf3999/y9/e3WR0+Pj7q16+fzdb/MCKUAgAAAAAAD7XXXnvN1iXojTfesHUJDx3GlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAZNnatWtlZ2enS5cuZXmegIAATZgw4b7Uk5SUpDJlyujXX3/N1nxz5syRl5fXfakpt8XExMjOzk47d+6UJO3fv18lSpTQ1atXbVvYPcpn6wIAAAAAAHhoDPM0eX1x2ererVs3zZ07V71799bUqVOtpr388suaPHmyIiIiNGfOnFws8t4NGzZMw4cPt7z28PBQ1apVNXLkSDVq1OiO806dOlWBgYGqV6+eVfuaNWv0wQcf6Pfff9e1a9cUEBCg5s2bq1+/fipevPh92Q6zBAcHq06dOho/frwGDx5s63JyjCulAAAAAADIQ/z9/bVo0SJdu3bN0nb9+nUtXLhQJUuWtGFld1apUiWdPn1ap0+f1ubNm1W2bFm1bNlScXGZB3OGYeiTTz5Rjx49rNqnTZumJk2ayM/PT0uXLtX+/fs1depUxcXFady4cfd7U0wRGRmpKVOmKDk52dal5BihFAAAAAAAeUiNGjXk7++vZcuWWdqWLVumkiVLKiQkxKpvYmKi+vbtKx8fH7m4uKhBgwbaunWrVZ8VK1aoXLlycnV11aOPPqqYmJh069y4caPCwsLk6uoqf39/9e3bN9u3luXLl09+fn7y8/NTcHCwRowYoStXrujw4cOZzrNt2zYdO3ZMLVq0sLT99ddf6tu3r/r27atZs2apcePGCggIUMOGDTVjxgwNGTIk0+V9/fXXqlGjhlxcXFS6dGkNHz7cKvQZP368qlSpIjc3N/n7+6tPnz66cuWKZXraLYGrVq1SxYoV5e7urmbNmun06dNW65kxY4YqVqwoFxcXVahQQZMnT7aavmXLFoWEhMjFxUU1a9bUjh070tX6xBNP6MKFC1q3bl3mb+oDjlAKAAAAAIA8pnv37po9e7bl9axZsxQZGZmu34ABA7R06VLNnTtX27dvV5kyZRQeHq4LFy5Ikk6dOqVnnnlGrVq10s6dO9WzZ08NHDjQahnHjh1Ts2bN1LZtW+3evVuLFy/Wxo0bFRUVleP6ExMTNXv2bHl5eal8+fKZ9tuwYYPKlSunAgUKWNqWLFmipKQkDRgwIMN5MhtHasOGDeratateffVV7d+/X9OmTdOcOXM0atQoSx97e3tNnDhR+/bt09y5c/XLL7+kW09CQoLGjh2r+fPna/369Tp58qTefPNNy/QFCxZoyJAhGjVqlA4cOKD33ntPgwcP1ty5cyVJV65cUcuWLRUcHKxt27Zp2LBhVvOncXJyUvXq1bVhw4ZM358HHaEUAAAAAAB5TJcuXbRx40adOHFCJ06c0KZNm9SlSxerPlevXtWUKVP0wQcfqHnz5goODtb06dPl6uqqmTNnSpKmTJmioKAgjRs3TuXLl1fnzp3VrVs3q+VER0erc+fOeu2111S2bFnVq1dPEydO1Lx583T9+vUs17xnzx65u7vL3d1drq6uGjt2rD7//HN5eHhkOs+JEydUrFgxq7YjR47Iw8NDRYsWzfK6JWn48OEaOHCgIiIiVLp0aT3xxBN69913NW3aNEuf1157TY8++qgCAgL02GOPaeTIkfriiy+slnPjxg1NnTpVNWvWVI0aNRQVFaXVq1dbpg8dOlTjxo3TM888o8DAQD3zzDN6/fXXLetZuHChUlNTNXPmTFWqVEktW7ZU//79M6y5WLFiOnHiRLa280HCQOcAAAAAAOQxRYoUUYsWLTRnzhwZhqEWLVrI29vbqs+xY8d048YN1a9f39Lm6OioWrVq6cCBA5KkAwcOqHbt2lbz1a1b1+r1rl27tHv3bi1YsMDSZhiGUlNTdfz4cVWsWDFLNZcvX17ffPONJOny5ctavHixnn32Wa1Zs0Y1a9bMcJ5r167JxcXFqs0wDNnZ2WVpnbdvx6ZNm6yujEpJSdH169eVkJCg/Pnz6+eff1Z0dLQOHjyo+Ph4JScnW02XpPz58ysoKMiyjKJFiyo2NlbSzSDw2LFj6tGjh3r16mXpk5ycLE/Pm4PoHzhwQFWrVrXartvf8zSurq5KSEjI9rY+KAilAAAAAADIg7p37265hW7SpEn3bT1XrlxR79691bdv33TTsjOwupOTk8qUKWN5HRISouXLl2vChAn67LPPMpzH29tbe/bssWorV66c4uLidPr06WxdLXXlyhUNHz5czzzzTLppLi4uiomJUcuWLfXSSy9p1KhRKlSokDZu3KgePXooKSnJEko5OjpazWtnZyfDMCzrkKTp06enC/scHByyXGuaCxcuWAVgDxtu3wMAAAAAIA9q1qyZkpKSdOPGDYWHh6ebHhQUJCcnJ23atMnSduPGDW3dulXBwcGSpIoVK2rLli1W8/32229Wr2vUqKH9+/erTJky6X6cnJzuaRscHBysniJ4u5CQEB08eNAS+khSu3bt5OTkpPfffz/DeS5dupRhe40aNXTo0KEMt8Pe3l7btm1Tamqqxo0bpzp16qhcuXL6559/srU9vr6+KlasmP7888906wgMDJR08z3fvXu31a2Pt7/nafbu3Ztu8PqHCVdKAQAAAACQBzk4OFhuw8voKhw3Nze99NJL6t+/vwoVKqSSJUvq/fffV0JCgnr06CFJevHFFzVu3Dj1799fPXv21LZt2zRnzhyr5bz11luqU6eOoqKi1LNnT7m5uWn//v366aef9Mknn2S53uTkZJ05c0bS/92+t3//fr311luZzvPoo4/qypUr2rdvnypXrixJ8vf314cffqioqCjFx8era9euCggI0F9//aV58+bJ3d1d48aNS7esIUOGqGXLlipZsqTatWsne3t77dq1S3v37tXIkSNVpkwZ3bhxQx9//LFatWqlTZs2aerUqVnevjTDhw9X37595enpqWbNmikxMVF//PGHLl68qH79+qlTp05655131KtXLw0aNEgxMTEaO3ZsuuXExMTo77//VpMmTbJdw4OCK6UAAAAAAMijPDw87jhQ+OjRo9W2bVs9//zzqlGjho4ePapVq1apYMGCkm7efrd06VItX75c1apV09SpU/Xee+9ZLaNq1apat26dDh8+rLCwMIWEhGjIkCHpBiC/m3379qlo0aIqWrSoqlevri+++EJTpkxR165dM52ncOHCatOmjdV4VpLUp08f/fjjj/r777/Vpk0bVahQQT179pSHh0eGT7KTpPDwcH333Xf68ccf9cgjj6hOnTr68MMPVapUKUlStWrVNH78eI0ZM0aVK1fWggULFB0dna1tlKSePXtqxowZmj17tqpUqaJGjRppzpw5liul3N3d9e2332rPnj0KCQnRO++8ozFjxqRbzueff66mTZta6nsY2Rm3XuP2HxAfHy9PT0/FxcXd8cAEAAAAAPw3Xb9+XcePH1dgYGC6QbTx4Nm9e7eeeOIJHTt2TO7u7rYuxxRJSUkqW7asFi5caDVQvZnudJxkNXvhSikAAAAAAPDQqlq1qsaMGaPjx4/buhTTnDx5Um+//bbNAqncwphSAAAAAADgodatWzdbl2CqtMHRH3ZcKQUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAyLK1a9fKzs5Oly5dyvI8AQEBmjBhwn2rqWHDhlq4cOF9W35eFxMTIzs7O+3cuVOStH//fpUoUUJXr169r+vNd1+XDgAAAABAHlJlbhVT17cnYk+2+nfr1k1z585V7969NXXqVKtpL7/8siZPnqyIiAjNmTMnF6vMHfHx8RozZoyWLl2qmJgYeXl5qXLlyurTp4/atGkjOzu7DOf75ptvdPbsWT333HPppkVHR+t///ufRo8erf79+9/vTTBVTEyMAgMDtWPHDlWvXj1Xlx0cHKw6depo/PjxGjx4cK4u+1ZcKQUAAAAAQB7i7++vRYsW6dq1a5a269eva+HChSpZsqQNK8vcpUuXVK9ePc2bN0+DBg3S9u3btX79enXo0EEDBgxQXFxcpvNOnDhRkZGRsrdPH3HMmjVLAwYM0KxZs+5n+XlSZGSkpkyZouTk5Pu2DkIpAAAAAADykBo1asjf31/Lli2ztC1btkwlS5ZUSEiIVd/ExET17dtXPj4+cnFxUYMGDbR161arPitWrFC5cuXk6uqqRx99VDExMenWuXHjRoWFhcnV1VX+/v7q27dvtm79evvttxUTE6Pff/9dERERCg4OVrly5dSrVy/t3LlT7u7uGc537tw5/fLLL2rVqlW6aevWrdO1a9c0YsQIxcfH69dff7Wa3q1bN7Vu3dqq7bXXXlPjxo0try9fvqzOnTvLzc1NRYsW1YcffqjGjRvrtddes/QJCAjQyJEj1bVrV7m7u6tUqVL65ptvdO7cOT399NNyd3dX1apV9ccff2TrPQsICNB7772n7t27q0CBAipZsqQ+/fRTy/TAwEBJUkhIiOzs7KzqnjFjhipWrCgXFxdVqFBBkydPtlr3li1bFBISIhcXF9WsWVM7duxI9/498cQTunDhgtatW5duWm4hlAIAAAAAII/p3r27Zs+ebXk9a9YsRUZGpus3YMAALV26VHPnztX27dtVpkwZhYeH68KFC5KkU6dO6ZlnnlGrVq20c+dO9ezZUwMHDrRaxrFjx9SsWTO1bdtWu3fv1uLFi7Vx40ZFRUVlqdbU1FQtWrRInTt3VrFixdJNd3d3V758GY8+tHHjRuXPn18VK1ZMN23mzJnq2LGjHB0d1bFjR82cOTNL9dyqX79+2rRpk7755hv99NNP2rBhg7Zv356u34cffqj69etrx44datGihZ5//nl17dpVXbp00fbt2xUUFKSuXbvKMAxJWX/Pxo0bZwmN+vTpo5deekmHDh2SdDNYkqSff/5Zp0+ftoSQCxYs0JAhQzRq1CgdOHBA7733ngYPHqy5c+dKkq5cuaKWLVsqODhY27Zt07Bhw/Tmm2+m2yYnJydVr15dGzZsyPb7llWEUgAAAAAA5DFdunTRxo0bdeLECZ04cUKbNm1Sly5drPpcvXpVU6ZM0QcffKDmzZsrODhY06dPl6urqyXAmTJlioKCgjRu3DiVL19enTt3Vrdu3ayWEx0drc6dO+u1115T2bJlVa9ePU2cOFHz5s3T9evX71rr+fPndfHiRVWoUCHb23nixAn5+vqmu3UvPj5eX375pWWbu3Tpoi+++EJXrlzJ8rIvX76suXPnauzYsXr88cdVuXJlzZ49WykpKen6Pvnkk+rdu7fKli2rIUOGKD4+Xo888oieffZZlStXTm+99ZYOHDigs2fPSsr6e/bkk0+qT58+KlOmjN566y15e3trzZo1kqQiRYpIkgoXLiw/Pz8VKlRIkjR06FCNGzdOzzzzjAIDA/XMM8/o9ddf17Rp0yRJCxcuVGpqqmbOnKlKlSqpZcuWmY63VaxYMZ04cSLL71l2MdA5AAAAAAB5TJEiRdSiRQvNmTNHhmGoRYsW8vb2tupz7Ngx3bhxQ/Xr17e0OTo6qlatWjpw4IAk6cCBA6pdu7bVfHXr1rV6vWvXLu3evVsLFiywtBmGodTUVB0/fjzDq5hulXb1UE5cu3ZNLi4u6do///xzBQUFqVq1apKk6tWrq1SpUlq8eLF69OiRpWX/+eefunHjhmrVqmVp8/T0VPny5dP1rVq1quX/fX19JUlVqlRJ1xYbGys/P78sv2e3LtfOzk5+fn6KjY3NtOarV6/q2LFj6tGjh3r16mVpT05Olqenp6Sbn2nVqlWt3rfbP9M0rq6uSkhIyHR994pQCgAAAACAPKh79+6W28EmTZp039Zz5coV9e7dW3379k03LSsDqxcpUkReXl46ePBgttft7e2tixcvpmufOXOm9u3bZ3XbX2pqqmbNmmUJpezt7dMFYjdu3Mh2DdLNMC9N2lMCM2pLTU2VlPX37NZlpC0nbRkZSbsSbPr06enCRAcHhyxty60uXLigoKCgbM+XVYRSAAAAAADkQc2aNVNSUpLs7OwUHh6ebnpQUJCcnJy0adMmlSpVStLNUGbr1q2WgbwrVqyob775xmq+3377zep1jRo1tH//fpUpUyZHddrb2+u5557T/PnzNXTo0HTjSl25ckUuLi4ZjisVEhKiM2fO6OLFiypYsKAkac+ePfrjjz+0du1ayy1t0s2ApXHjxjp48KAqVKigIkWKaO/evVbL27lzpyUIKl26tBwdHbV161ZLUBQXF6fDhw+rYcOGOdrWNPf6nkk3x3ySZHU7oa+vr4oVK6Y///xTnTt3znC+ihUrav78+bp+/brlaqnbP9M0e/fuVbt27XJc490wphQAAAAAAHmQg4ODDhw4oP3792d4lYybm5teeukl9e/fXytXrtT+/fvVq1cvJSQkWK4mevHFF3XkyBH1799fhw4d0sKFCzVnzhyr5bz11lv69ddfFRUVpZ07d+rIkSP6+uuvszzQuSSNGjVK/v7+ql27tubNm6f9+/fryJEjmjVrlkJCQjIdCyokJETe3t7atGmTpW3mzJmqVauWGjZsqMqVK1t+GjZsqEceecQyXtZjjz2mP/74Q/PmzdORI0c0dOhQq5CqQIECioiIUP/+/bVmzRrt27dPPXr0kL29veXKp5zKjffMx8dHrq6uWrlypc6ePau4uDhJ0vDhwxUdHa2JEyfq8OHD2rNnj2bPnq3x48dLkjp16iQ7Ozv16tVL+/fv14oVKzR27Nh0y4+JidHff/+tJk2a3NO23gmhFAAAAAAAeZSHh4c8PDwynT569Gi1bdtWzz//vGrUqKGjR49q1apVlquOSpYsqaVLl2r58uWqVq2apk6dqvfee89qGVWrVtW6det0+PBhhYWFKSQkREOGDMnwSXqZKVSokH777Td16dJFI0eOVEhIiMLCwvT555/rgw8+sIyHdDsHBwdFRkZaxmZKSkrSZ599prZt22bYv23btpo3b55u3Lih8PBwDR48WAMGDNAjjzyiy5cvq2vXrlb9x48fr7p166ply5Zq0qSJ6tevr4oVK2Y4jlV25MZ7li9fPk2cOFHTpk1TsWLF9PTTT0uSevbsqRkzZmj27NmqUqWKGjVqpDlz5igwMFDSzacZfvvtt9qzZ49CQkL0zjvvaMyYMemW//nnn6tp06aWq+juBzvjXkYUewjFx8fL09NTcXFxdzwwAQAAAAD/TdevX9fx48cVGBh4z+ED7r8zZ86oUqVK2r59+30NUKSbA4kXL15c48aNy/KA6Q+jpKQklS1bVgsXLrQaCP9WdzpOspq9cKUUAAAAAAB4aPn5+WnmzJk6efJkri97x44d+vzzz3Xs2DFt377dMk5T2lVJedXJkyf19ttvZxpI5RYGOgcAAAAAAA+11q1b37dljx07VocOHZKTk5NCQ0O1YcMGeXt737f1PQjKlClzT4OwZxWhFAAAAAAAQAZCQkK0bds2W5eRZ3H7HgAAAAAAAExHKAUAAAAAQAb+Y88FA7IlN44PQikAAAAAAG7h6OgoSUpISLBxJcCDK+34SDtecoIxpQAAAAAAuIWDg4O8vLwUGxsrScqfP7/s7OxsXBXwYDAMQwkJCYqNjZWXl5ccHBxyvCxCKQAAAAAAbuPn5ydJlmAKgDUvLy/LcZJThFIAAAAAANzGzs5ORYsWlY+Pj27cuGHrcoAHiqOj4z1dIZWGUAoAAAAAgEw4ODjkyh/fANJjoHMAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGC6ByKUmjRpkgICAuTi4qLatWtry5YtWZpv0aJFsrOzU+vWre9vgQAAAAAAAMhVNg+lFi9erH79+mno0KHavn27qlWrpvDwcMXGxt5xvpiYGL355psKCwszqVIAAAAAAADkFpuHUuPHj1evXr0UGRmp4OBgTZ06Vfnz59esWbMynSclJUWdO3fW8OHDVbp0aROrBQAAAAAAQG6waSiVlJSkbdu2qUmTJpY2e3t7NWnSRJs3b850vhEjRsjHx0c9evS46zoSExMVHx9v9QMAAAAAAADbsmkodf78eaWkpMjX19eq3dfXV2fOnMlwno0bN2rmzJmaPn16ltYRHR0tT09Py4+/v/891w0AAAAAAIB7Y/Pb97Lj8uXLev755zV9+nR5e3tnaZ5BgwYpLi7O8nPq1Kn7XCUAAAAAAADuJp8tV+7t7S0HBwedPXvWqv3s2bPy8/NL1//YsWOKiYlRq1atLG2pqamSpHz58unQoUMKCgqymsfZ2VnOzs73oXoAAAAAAADklE2vlHJyclJoaKhWr15taUtNTdXq1atVt27ddP0rVKigPXv2aOfOnZafp556So8++qh27tzJrXkAAAAAAAAPCZteKSVJ/fr1U0REhGrWrKlatWppwoQJunr1qiIjIyVJXbt2VfHixRUdHS0XFxdVrlzZan4vLy9JStcOAAAAAACAB5fNQ6kOHTro3LlzGjJkiM6cOaPq1atr5cqVlsHPT548KXv7h2roKwAAAAAAANyFnWEYhq2LMFN8fLw8PT0VFxcnDw8PW5cDAAAAAACQp2Q1e7H5lVK4NwEDv7d1CfddzOgWti4BAADcZ/xOAwDAfw/3xQEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0+WxdAHBXwzxtXcH9NSzO1hUAAAAz8DsNAABWuFIKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYLp+tCwAAAAAAwAwBA7+3dQn3VczoFrYuAcgWQikAwF3xCxwAAACA3MbtewAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADBdPlsXAAAAAAAAcsEwT1tXcP8Ni7N1BchFhFIAAPALHAAAAGA6bt8DAAAAAACA6bhSCrCxKnOr2LqE+25PxB5blwAAAO4zfqcBAGQXV0oBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADT5bN1AQAA4P6rMreKrUu4r/ZE7LF1CQAAAMgmrpQCAAAAAACA6QilAAAAAAAAYDpu3wMAAAAAAA8FhiTIW7hSCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmO6BCKUmTZqkgIAAubi4qHbt2tqyZUumfZctW6aaNWvKy8tLbm5uql69uubPn29itQAAAAAAALhXNg+lFi9erH79+mno0KHavn27qlWrpvDwcMXGxmbYv1ChQnrnnXe0efNm7d69W5GRkYqMjNSqVatMrhwAAAAAAAA5ZfNQavz48erVq5ciIyMVHBysqVOnKn/+/Jo1a1aG/Rs3bqw2bdqoYsWKCgoK0quvvqqqVatq48aNJlcOAAAAAACAnLJpKJWUlKRt27apSZMmljZ7e3s1adJEmzdvvuv8hmFo9erVOnTokBo2bJhhn8TERMXHx1v9AAAAAAAAwLZsGkqdP39eKSkp8vX1tWr39fXVmTNnMp0vLi5O7u7ucnJyUosWLfTxxx/riSeeyLBvdHS0PD09LT/+/v65ug0AAAAAAADIPpvfvpcTBQoU0M6dO7V161aNGjVK/fr109q1azPsO2jQIMXFxVl+Tp06ZW6xAAAAAAAASCefLVfu7e0tBwcHnT171qr97Nmz8vPzy3Q+e3t7lSlTRpJUvXp1HThwQNHR0WrcuHG6vs7OznJ2ds7VugEAAAAAAHBvbHqllJOTk0JDQ7V69WpLW2pqqlavXq26detmeTmpqalKTEy8HyUCAAAAAADgPrDplVKS1K9fP0VERKhmzZqqVauWJkyYoKtXryoyMlKS1LVrVxUvXlzR0dGSbo4RVbNmTQUFBSkxMVErVqzQ/PnzNWXKFFtuBgAAAAAAALLB5qFUhw4ddO7cOQ0ZMkRnzpxR9erVtXLlSsvg5ydPnpS9/f9d0HX16lX16dNHf/31l1xdXVWhQgV99tln6tChg602AQAAAAAAANlk81BKkqKiohQVFZXhtNsHMB85cqRGjhxpQlUAAAAAAAC4Xx7Kp+8BAAAAAADg4UYoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAw3T2FUklJSTp06JCSk5Nzqx4AAAAAAAD8B+QolEpISFCPHj2UP39+VapUSSdPnpQkvfLKKxo9enSuFggAAAAAAIC8J0eh1KBBg7Rr1y6tXbtWLi4ulvYmTZpo8eLFuVYcAAAAAAAA8qZ8OZlp+fLlWrx4serUqSM7OztLe6VKlXTs2LFcKw4AAAAAAAB5U46ulDp37px8fHzStV+9etUqpAIAAAAAAAAykqNQqmbNmvr+++8tr9OCqBkzZqhu3bq5UxkAAAAAAADyrBzdvvfee++pefPm2r9/v5KTk/XRRx9p//79+vXXX7Vu3brcrhEAAAAAAAB5TI6ulGrQoIF27dql5ORkValSRT/++KN8fHy0efNmhYaG5naNAAAAAAAAyGOyfaXUjRs31Lt3bw0ePFjTp0+/HzUBAAAAAAAgj8v2lVKOjo5aunTp/agFAAAAAAAA/xE5un2vdevWWr58eS6XAgAAAAAAgP+KHA10XrZsWY0YMUKbNm1SaGio3NzcrKb37ds3V4oDAAAAAABA3pSjUGrmzJny8vLStm3btG3bNqtpdnZ2hFIAAAAAAAC4oxyFUsePH8/tOgAAAAAAAPAfkqMxpW5lGIYMw8iNWgAAAAAAAPAfkeNQat68eapSpYpcXV3l6uqqqlWrav78+blZGwAAAAAAAPKoHN2+N378eA0ePFhRUVGqX7++JGnjxo168cUXdf78eb3++uu5WiQAAAAAAADylhyFUh9//LGmTJmirl27WtqeeuopVapUScOGDSOUAgAAAAAAwB3l6Pa906dPq169euna69Wrp9OnT99zUQAAAAAAAMjbchRKlSlTRl988UW69sWLF6ts2bL3XBQAAAAAAADythzdvjd8+HB16NBB69evt4wptWnTJq1evTrDsAoAAAAAAAC4VY6ulGrbtq1+//13eXt7a/ny5Vq+fLm8vb21ZcsWtWnTJrdrBAAAAAAAQB6ToyulJCk0NFSfffZZbtYCAAAAAACA/4gcXSm1YsUKrVq1Kl37qlWr9MMPP9xzUQAAAAAAAMjbchRKDRw4UCkpKenaDcPQwIED77koAAAAAAAA5G05CqWOHDmi4ODgdO0VKlTQ0aNH77koAAAAAAAA5G05CqU8PT31559/pms/evSo3Nzc7rkoAAAAAAAA5G05CqWefvppvfbaazp27Jil7ejRo3rjjTf01FNP5VpxAAAAAAAAyJtyFEq9//77cnNzU4UKFRQYGKjAwEBVqFBBhQsX1tixY3O7RgAAAAAAAOQx+XIyk6enp3799Vf99NNP2rVrl1xdXVWtWjWFhYXldn0AAAAAAADIg7J1pdTmzZv13XffSZLs7OzUtGlT+fj4aOzYsWrbtq1eeOEFJSYm3pdCAQAAAAAAkHdkK5QaMWKE9u3bZ3m9Z88e9erVS0888YQGDhyob7/9VtHR0bleJAAAAAAAAPKWbIVSO3fu1OOPP255vWjRItWqVUvTp09Xv379NHHiRH3xxRe5XiQAAAAAAADylmyFUhcvXpSvr6/l9bp169S8eXPL60ceeUSnTp3KveoAAAAAAACQJ2UrlPL19dXx48clSUlJSdq+fbvq1KljmX758mU5OjrmboUAAAAAAADIc7IVSj355JMaOHCgNmzYoEGDBil//vxWT9zbvXu3goKCcr1IAAAAAAAA5C35stP53Xff1TPPPKNGjRrJ3d1dc+fOlZOTk2X6rFmz1LRp01wvEgAAAAAAAHlLtkIpb29vrV+/XnFxcXJ3d5eDg4PV9CVLlsjd3T1XCwQAAAAAAEDek61QKo2np2eG7YUKFbqnYgAAAAAAAPDfkK0xpQAAAAAAAIDcQCgFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0z0QodSkSZMUEBAgFxcX1a5dW1u2bMm07/Tp0xUWFqaCBQuqYMGCatKkyR37AwAAAAAA4MFj81Bq8eLF6tevn4YOHart27erWrVqCg8PV2xsbIb9165dq44dO2rNmjXavHmz/P391bRpU/39998mVw4AAAAAAICcsnkoNX78ePXq1UuRkZEKDg7W1KlTlT9/fs2aNSvD/gsWLFCfPn1UvXp1VahQQTNmzFBqaqpWr15tcuUAAAAAAADIKZuGUklJSdq2bZuaNGliabO3t1eTJk20efPmLC0jISFBN27cUKFChe5XmQAAAAAAAMhl+Wy58vPnzyslJUW+vr5W7b6+vjp48GCWlvHWW2+pWLFiVsHWrRITE5WYmGh5HR8fn/OCAQAAAAAAkCtsfvvevRg9erQWLVqkr776Si4uLhn2iY6Olqenp+XH39/f5CoBAAAAAABwO5uGUt7e3nJwcNDZs2et2s+ePSs/P787zjt27FiNHj1aP/74o6pWrZppv0GDBikuLs7yc+rUqVypHQAAAAAAADln01DKyclJoaGhVoOUpw1aXrdu3Uzne//99/Xuu+9q5cqVqlmz5h3X4ezsLA8PD6sfAAAAAAAA2JZNx5SSpH79+ikiIkI1a9ZUrVq1NGHCBF29elWRkZGSpK5du6p48eKKjo6WJI0ZM0ZDhgzRwoULFRAQoDNnzkiS3N3d5e7ubrPtAAAAAAAAQNbZPJTq0KGDzp07pyFDhujMmTOqXr26Vq5caRn8/OTJk7K3/78LuqZMmaKkpCS1a9fOajlDhw7VsGHDzCwdAAAAAAAAOWTzUEqSoqKiFBUVleG0tWvXWr2OiYm5/wUBAAAAAADgvnqon74HAAAAAACAhxOhFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExn81Bq0qRJCggIkIuLi2rXrq0tW7Zk2nffvn1q27atAgICZGdnpwkTJphXKAAAAAAAAHKNTUOpxYsXq1+/fho6dKi2b9+uatWqKTw8XLGxsRn2T0hIUOnSpTV69Gj5+fmZXC0AAAAAAAByi01DqfHjx6tXr16KjIxUcHCwpk6dqvz582vWrFkZ9n/kkUf0wQcf6LnnnpOzs7PJ1QIAAAAAACC32CyUSkpK0rZt29SkSZP/K8beXk2aNNHmzZttVRYAAAAAAABMkM9WKz5//rxSUlLk6+tr1e7r66uDBw/m2noSExOVmJhoeR0fH59rywYAAAAAAEDO2Hyg8/stOjpanp6elh9/f39blwQAAAAAAPCfZ7NQytvbWw4ODjp79qxV+9mzZ3N1EPNBgwYpLi7O8nPq1KlcWzYAAAAAAAByxmahlJOTk0JDQ7V69WpLW2pqqlavXq26devm2nqcnZ3l4eFh9QMAAAAAAADbstmYUpLUr18/RUREqGbNmqpVq5YmTJigq1evKjIyUpLUtWtXFS9eXNHR0ZJuDo6+f/9+y////fff2rlzp9zd3VWmTBmbbQcAAAAAAACyx6ahVIcOHXTu3DkNGTJEZ86cUfXq1bVy5UrL4OcnT56Uvf3/Xcz1zz//KCQkxPJ67NixGjt2rBo1aqS1a9eaXT4AAAAAAAByyKahlCRFRUUpKioqw2m3B00BAQEyDMOEqgAAAAAAAHA/5fmn7wEAAAAAAODBQygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0z0QodSkSZMUEBAgFxcX1a5dW1u2bLlj/yVLlqhChQpycXFRlSpVtGLFCpMqBQAAAAAAQG6weSi1ePFi9evXT0OHDtX27dtVrVo1hYeHKzY2NsP+v/76qzp27KgePXpox44dat26tVq3bq29e/eaXDkAAAAAAAByyuah1Pjx49WrVy9FRkYqODhYU6dOVf78+TVr1qwM+3/00Udq1qyZ+vfvr4oVK+rdd99VjRo19Mknn5hcOQAAAAAAAHLKpqFUUlKStm3bpiZNmlja7O3t1aRJE23evDnDeTZv3mzVX5LCw8Mz7Q8AAAAAAIAHTz5brvz8+fNKSUmRr6+vVbuvr68OHjyY4TxnzpzJsP+ZM2cy7J+YmKjExETL67i4OElSfHz8vZT+wEhNTLB1CfddvJ1h6xLuq5RrKbYu4b7LK8fbf1leP9fk9fOMlPfPNZxnHn55/Twj5f1zTV4/z0ica/KCvH6uyevnGSnvn2vyynkmbTsM4877pE1DKTNER0dr+PDh6dr9/f1tUA1ywtPWBdx3B2xdwH3n+VLe/xTxcPtv7KF5+1zDeQYPg7y/l+bt84zEuQYPvv/GHpq3zzV57Txz+fJleXpmvk02DaW8vb3l4OCgs2fPWrWfPXtWfn5+Gc7j5+eXrf6DBg1Sv379LK9TU1N14cIFFS5cWHZ2dve4Bchr4uPj5e/vr1OnTsnDw8PW5QDIgzjPADAD5xoA9xvnGdyJYRi6fPmyihUrdsd+Ng2lnJycFBoaqtWrV6t169aSboZGq1evVlRUVIbz1K1bV6tXr9Zrr71mafvpp59Ut27dDPs7OzvL2dnZqs3Lyys3ykce5uHhwYkVwH3FeQaAGTjXALjfOM8gM3e6QiqNzW/f69evnyIiIlSzZk3VqlVLEyZM0NWrVxUZGSlJ6tq1q4oXL67o6GhJ0quvvqpGjRpp3LhxatGihRYtWqQ//vhDn376qS03AwAAAAAAANlg81CqQ4cOOnfunIYMGaIzZ86oevXqWrlypWUw85MnT8re/v8eElivXj0tXLhQ//vf//T222+rbNmyWr58uSpXrmyrTQAAAAAAAEA22TyUkqSoqKhMb9dbu3ZturZnn31Wzz777H2uCv9Fzs7OGjp0aLpbPgEgt3CeAWAGzjUA7jfOM8gNdsbdns8HAAAAAAAA5DL7u3cBAAAAAAAAchehFAAAAAAAAExHKAUAgMns7Oy0fPnyXO8LALnh1vNOTEyM7OzstHPnTpvWBADImwil8EDbvHmzHBwc1KJFC1uXAiCP6tatm+zs7GRnZycnJyeVKVNGI0aMUHJy8n1b5+nTp9W8efNc7wvg4XfrOcnR0VGBgYEaMGCArl+/buvSADwEbj2H3Ppz9OhRrV+/Xq1atVKxYsX4Ry88MAil8ECbOXOmXnnlFa1fv17//POPzepISkqy2boB3H/NmjXT6dOndeTIEb3xxhsaNmyYPvjgg3T9cutc4Ofnl+Un1WSnL4C8Ie2c9Oeff+rDDz/UtGnTNHToUFuXBeAhkXYOufUnMDBQV69eVbVq1TRp0iRbl5gp/u767yGUwgPrypUrWrx4sV566SW1aNFCc+bMsZr+7bff6pFHHpGLi4u8vb3Vpk0by7TExES99dZb8vf3l7Ozs8qUKaOZM2dKkubMmSMvLy+rZS1fvlx2dnaW18OGDVP16tU1Y8YMBQYGysXFRZK0cuVKNWjQQF5eXipcuLBatmypY8eOWS3rr7/+UseOHVWoUCG5ubmpZs2a+v333xUTEyN7e3v98ccfVv0nTJigUqVKKTU19V7fMgA55OzsLD8/P5UqVUovvfSSmjRpom+++UbdunVT69atNWrUKBUrVkzly5eXJJ06dUrt27eXl5eXChUqpKeffloxMTFWy5w1a5YqVaokZ2dnFS1aVFFRUZZpt/7rZFJSkqKiolS0aFG5uLioVKlSio6OzrCvJO3Zs0ePPfaYXF1dVbhwYb3wwgu6cuWKZXpazWPHjlXRokVVuHBhvfzyy7px40buv3EA7ou0c5K/v79at26tJk2a6KeffpIkpaamKjo6WoGBgXJ1dVW1atX05ZdfWs2/b98+tWzZUh4eHipQoIDCwsIsv6/8v/buNaiq6+7j+BeOQpCLgqAEq6AVhQawQExrbYoYVCB14p1SVLzEjlV0hLFttE01YyakZuwkxojGIqJGjAa1REy9IJp4kiposNISAkhCYttoNZl6jIrCel503I8n4u15EEz6+8ycF+513XuG5V7/s9Y6ZWVlDBs2DH9/fzp37kxcXBzHjh1r83sUkXvn2hhy/cdms5GUlMSzzz7rNG+6HWMMixcvplevXri7uxMUFMTcuXOt9FvNuwAOHjzII488Yr0PPfXUU06r0YcMGUJGRgbz5s3D39+fESNGAFBZWUlSUhJeXl50796dSZMm8a9//asVno7cbxSUkvvWli1bCAsLo3///kycOJG1a9dijAGguLiY0aNHk5yczPvvv09JSQmPPPKIVXby5MkUFBSwfPlyqqqqWL16NV5eXnfVfm1tLYWFhWzbts06R+HChQtkZWVRXl5OSUkJrq6ujB492gooORwO4uLiOHXqFEVFRRw/fpxf/vKXNDc3ExISQkJCAnl5eU7t5OXlMWXKFFxd9ecocr/w8PCwvqkrKSmhurqavXv3snPnTq5cucKIESPw9vbmnXfewW634+XlRWJiolUmJyeH2bNn87Of/YwTJ05QVFRE3759W2xr+fLlFBUVsWXLFqqrq3nttdcICQlpMe+FCxcYMWIEvr6+lJWVsXXrVvbt2+cU8AIoLS2lrq6O0tJS8vPzWbdu3Q2BfRH5eqisrOTdd9/Fzc0NgOzsbNavX8+qVav461//SmZmJhMnTuTgwYMAnDp1ih/96Ee4u7uzf/9+jh49yrRp06xJ4Pnz50lPT+fQoUP8+c9/JjQ0lOTkZM6fP99u9ygi96/CwkJrxWZNTQ07duwgMjLSSr/VvOvUqVMkJyczcOBAjh8/Tk5ODrm5uTz77LNObeTn5+Pm5obdbmfVqlV88cUXDB06lOjoaMrLy/nTn/7EZ599xoQJE9r03qWNGJH71A9+8APz4osvGmOMuXLlivH39zelpaXGGGMGDRpk0tLSWixXXV1tALN3794W0/Py8kznzp2drm3fvt1c/+ewaNEi07FjR3P69Olb9vHMmTMGMCdOnDDGGLN69Wrj7e1tzp4922L+119/3fj6+ppLly4ZY4w5evSocXFxMfX19bdsR0TunfT0dPPEE08YY4xpbm42e/fuNe7u7mb+/PkmPT3ddO/e3Vy+fNnKv2HDBtO/f3/T3NxsXbt8+bLx8PAwu3fvNsYYExQUZH7961/ftE3AbN++3RhjzJw5c8zQoUOd6rtZ3ldffdX4+voah8NhpRcXFxtXV1fzz3/+07qf4OBgc/XqVSvP+PHjTUpKyp0/FBFpN+np6cZmsxlPT0/j7u5uAOPq6mreeOMNc+nSJdOpUyfz7rvvOpWZPn26SU1NNcYYs2DBAtO7d2/T2Nh4R+01NTUZb29v8+abb1rXrh936uvrDWDef//9Vrk/Ebm3rh9Drn3GjRt3Q77r/85vZdmyZaZfv34tjim3m3ctXLjwhnemV155xXh5eZmmpiZjjDFxcXEmOjraqdySJUvM8OHDna598sknBjDV1dW37bN8vWhphtyXqqurOXLkCKmpqQB06NCBlJQUayloRUUFjz32WItlKyoqsNlsxMXF/b/6EBwcTEBAgNO1mpoaUlNT6dOnDz4+PtZqhoaGBqvt6Oho/Pz8Wqxz1KhR2Gw2tm/fDvxnK2F8fPxNV0WISNvYuXMnXl5ePPDAAyQlJZGSksLixYsBiIyMtFYoABw/fpza2lq8vb3x8vLCy8sLPz8/Ll26RF1dHadPn+bvf//7Tceor5oyZQoVFRX079+fuXPnsmfPnpvmraqqYsCAAXh6elrXBg8eTHNzM9XV1da1hx56CJvNZv37wQcf5PTp03f6OESkncXHx1NRUcHhw4dJT09n6tSpjB07ltraWr788kuGDRtmjT9eXl6sX7/e2p5XUVHBo48+SseOHVus+7PPPmPGjBmEhobSuXNnfHx8cDgc1ruMiHz9XRtDrn2WL19+R+Wee+45p7GloaGB8ePHc/HiRfr06cOMGTPYvn27tfLydvOuqqoqBg0a5HRMyuDBg3E4HHz66afWtdjYWKdyx48fp7S01KkvYWFhADccnSJffx3auwMiLcnNzeXq1asEBQVZ14wxuLu7s2LFCjw8PG5a9lZpAK6urtY2wGtaOmvl+knfNSNHjiQ4OJg1a9YQFBREc3MzERER1pad27Xt5ubG5MmTycvLY8yYMWzatImXXnrplmVE5N6Lj48nJycHNzc3goKC6NDhf/97/OpY4HA4iI2N5bXXXruhnoCAgLveihsTE0N9fT1vvfUW+/btY8KECSQkJNxwRszd+Opk1MXFRefWiXyNeHp6Wlt+165dy4ABA8jNzSUiIgL4zzEGPXr0cCpz7QcRbvcukp6eztmzZ3nppZcIDg7G3d2dQYMG6XBhkW+Q68eQuzFz5kynLXLX3omqq6vZt28fe/fuZdasWbzwwgscPHjwtuPN3fT3eg6Hg5EjR/K73/3uhrwPPvhgq7Qp9w8FpeS+c/XqVdavX8+yZcsYPny4U9qoUaMoKCggKiqKkpISpk6dekP5yMhImpubOXjwIAkJCTekBwQEcP78eS5cuGANgNfOjLqVs2fPUl1dzZo1a3j00UcBOHTokFOeqKgo/vCHP3Du3LmbrpZ68skniYiIYOXKlVy9epUxY8bctm0Rubfu5uUtJiaG119/nW7duuHj49NinpCQEEpKSoiPj7+jOn18fEhJSSElJYVx48aRmJjY4jgSHh7OunXrnMYvu92Oq6urdQi7iHyzuLq6snDhQrKysvjwww9xd3enoaHhpisToqKiyM/P58qVKy2ulrLb7axcuZLk5GTgPz/coMODRQTAz8+vxTmMh4cHI0eOZOTIkcyePZuwsDBOnDhx23lXeHg4hYWFGGOs1VJ2ux1vb2++9a1v3bQfMTExFBYWEhIS4vRFoXwzafue3Hd27tzJ559/zvTp04mIiHD6jB07ltzcXBYtWkRBQQGLFi2iqqqKEydOWJH0kJAQ0tPTmTZtGjt27KC+vp4DBw6wZcsWAL73ve/RqVMnFi5cSF1dHZs2bbqjA4B9fX3p2rUrr776KrW1tezfv5+srCynPKmpqQQGBjJq1CjsdjsnT56ksLCQ9957z8oTHh7O97//fX71q1+Rmpraat8wiEjbSEtLw9/fnyeeeIJ33nnHGmPmzp1rLUVfvHgxy5YtY/ny5dTU1HDs2DFefvnlFuv7/e9/T0FBAR988AEffvghW7duJTAw8IZfCb3W9gMPPEB6ejqVlZWUlpYyZ84cJk2aRPfu3e/lbYtIOxo/fjw2m43Vq1czf/58MjMzyc/Pp66uzhpf8vPzAcjIyODf//43P/nJTygvL6empoYNGzZYW3xDQ0PZsGEDVVVVHD58mLS0NL2LiPyXcDgc1pY+gPr6eioqKm65fXfdunXk5uZSWVnJyZMn2bhxIx4eHgQHB9923jVr1iw++eQT5syZwwcffMAf//hHFi1aRFZW1i1Xls+ePZtz586RmppKWVkZdXV17N69m6lTp9LU1NSqz0Tan4JSct/Jzc0lISGBzp0735A2duxYysvL8fPzY+vWrRQVFfHd736XoUOHcuTIEStfTk4O48aNY9asWYSFhTFjxgwuXLgA/OcbgI0bN7Jr1y4iIyMpKCiwzo65FVdXVzZv3szRo0eJiIggMzOTF154wSmPm5sbe/bsoVu3biQnJxMZGcnzzz/vdLYLwPTp02lsbGTatGn/hyckIu2pU6dOvP322/Tq1YsxY8YQHh7O9OnTuXTpkrVyKj09nRdffJGVK1fy0EMP8eMf/5iampoW6/P29mbp0qU8/PDDDBw4kI8++ohdu3a1+LLWqVMndu/ezblz5xg4cCDjxo3jscceY8WKFff0nkWkfXXo0IGMjAyWLl3KggULePrpp8nOziY8PJzExESKi4vp3bs3AF27dmX//v3WLwLHxsayZs0aa9VUbm4un3/+OTExMUyaNIm5c+fSrVu39rw9EWkj5eXlREdHEx0dDUBWVhbR0dH89re/vWmZLl26sGbNGgYPHkxUVBT79u3jzTffpGvXrsCt5109evRg165dHDlyhAEDBjBz5kymT5/Ob37zm1v2MygoCLvdTlNTE8OHDycyMpJ58+bRpUsX/WL5N5CL+erhOiJyzy1ZsoStW7fyl7/8pb27IiIiIiIiItIuFGYUaUMOh4PKykpWrFjBnDlz2rs7IiIiIiIiIu1GQSmRNpSRkUFsbCxDhgzR1j0RERERERH5r6bteyIiIiIiIiIi0ua0UkpERERERERERNqcglIiIiIiIiIiItLmFJQSEREREREREZE2p6CUiIiIiIiIiIi0OQWlRERERERERESkzSkoJSIiIvI15+Liwo4dO9q7GyIiIiJ3RUEpERERkVYwZcoUXFxcmDlz5g1ps2fPxsXFhSlTptxRXQcOHMDFxYUvvvjijvL/4x//ICkp6S56KyIiItL+FJQSERERaSU9e/Zk8+bNXLx40bp26dIlNm3aRK9evVq9vcbGRgACAwNxd3dv9fpFRERE7iUFpURERERaSUxMDD179mTbtm3WtW3bttGrVy+io6Ota83NzWRnZ9O7d288PDwYMGAAb7zxBgAfffQR8fHxAPj6+jqtsBoyZAgZGRnMmzcPf39/RowYAdy4fe/TTz8lNTUVPz8/PD09efjhhzl8+DAAx48fJz4+Hm9vb3x8fIiNjaW8vPxePhYRERGRFnVo7w6IiIiIfJNMmzaNvLw80tLSAFi7di1Tp07lwIEDVp7s7Gw2btzIqlWrCA0N5e2332bixIkEBATwwx/+kMLCQsaOHUt1dTU+Pj54eHhYZfPz8/n5z3+O3W5vsX2Hw0FcXBw9evSgqKiIwMBAjh07RnNzMwBpaWlER0eTk5ODzWajoqKCjh073rsHIiIiInITCkqJiIiItKKJEyeyYMECPv74YwDsdjubN2+2glKXL1/mueeeY9++fQwaNAiAPn36cOjQIVavXk1cXBx+fn4AdOvWjS5dujjVHxoaytKlS2/a/qZNmzhz5gxlZWVWPX379rXSGxoa+MUvfkFYWJhVn4iIiEh7UFBKREREpBUFBATw+OOPs27dOowxPP744/j7+1vptbW1fPnllwwbNsypXGNjo9MWv5uJjY29ZXpFRQXR0dFWQOqrsrKyePLJJ9mwYQMJCQmMHz+eb3/723dwZyIiIiKtS0EpERERkVY2bdo0MjIyAHjllVec0hwOBwDFxcX06NHDKe1ODiv39PS8Zfr1W/1asnjxYn76059SXFzMW2+9xaJFi9i8eTOjR4++bdsiIiIirUkHnYuIiIi0ssTERBobG7ly5Yp1GPk13/nOd3B3d6ehoYG+ffs6fXr27AmAm5sbAE1NTXfddlRUFBUVFZw7d+6mefr160dmZiZ79uxhzJgx5OXl3XU7IiIiIv9fCkqJiIiItDKbzUZVVRV/+9vfsNlsTmne3t7Mnz+fzMxM8vPzqaur49ixY7z88svk5+cDEBwcjIuLCzt37uTMmTPW6qo7kZqaSmBgIKNGjcJut3Py5EkKCwt57733uHjxIhkZGRw4cICPP/4Yu91OWVkZ4eHhrXr/IiIiIndCQSkRERGRe8DHxwcfH58W05YsWcLTTz9NdnY24eHhJCYmUlxcTO/evQHo0aMHzzzzDE899RTdu3e3tgLeCTc3N/bs2UO3bt1ITk4mMjKS559/HpvNhs1m4+zZs0yePJl+/foxYcIEkpKSeOaZZ1rlnkVERETuhosxxrR3J0RERERERERE5L+LVkqJiIiIiIiIiEibU1BKRERERERERETanIJSIiIiIiIiIiLS5hSUEhERERERERGRNqeglIiIiIiIiIiItDkFpUREREREREREpM0pKCUiIiIiIiIiIm1OQSkREREREREREWlzCkqJiIiIiIiIiEibU1BKRERERERERETanIJSIiIiIiIiIiLS5hSUEhERERERERGRNvc/G/QQeeLZi7MAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bar chart visualization of model performance completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dffe73d4"
      },
      "source": [
        "## Analysis and Conclusion\n",
        "\n",
        "### Subtask:\n",
        "Provide a detailed written analysis. Explain which preprocessing technique (if any) led to the most significant improvements, discuss why BERT's performance might have improved with cleaned text, and draw a conclusion regarding the achievement of your research gap by synthesizing the experimental results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9039d143"
      },
      "source": [
        "## Analysis and Conclusion\n",
        "\n",
        "Based on the comparison table and the bar chart visualizing the model performances, we can draw several conclusions regarding the impact of text preprocessing and data augmentation on BERT model performance for tweet sentiment classification.\n",
        "\n",
        "### Performance Overview:\n",
        "\n",
        "| Model             | Accuracy | Precision | Recall   | F1-score |\n",
        "|:------------------|:---------|:----------|:---------|:---------|\n",
        "| Model A (Raw)     | 0.394750 | 0.371082  | 0.394750 | 0.372071 |\n",
        "| Model B (Cleaned) | 0.386125 | 0.361949  | 0.386125 | 0.362607 |\n",
        "| Model C (Augmented)| 0.360250 | 0.333433  | 0.360250 | 0.330328 |\n",
        "\n",
        "\n",
        "From the metrics, **Model A (Raw Text)** achieved the best overall performance across all evaluated metrics (Accuracy, Precision, Recall, F1-score).\n",
        "\n",
        "### Detailed Analysis:\n",
        "\n",
        "1.  **Model A (Raw Text)**: This model, trained on the original, unprocessed tweet content, surprisingly performed the best. It achieved the highest accuracy of approximately 39.48% and the highest F1-score of approximately 37.21%. This suggests that for this specific dataset and BERT-base-uncased model, the raw, unfiltered text contains sufficient context or linguistic cues that BERT is able to leverage effectively, or that our cleaning process inadvertently removed some useful information.\n",
        "\n",
        "2.  **Model B (Cleaned Text)**: The model trained on cleaned text showed a slight degradation in performance compared to the raw text model. Its accuracy dropped to 38.61% and F1-score to 36.26%. This outcome was somewhat unexpected, as text cleaning is generally assumed to improve model performance by reducing noise. Possible reasons for this slight dip could include:\n",
        "    *   **Removal of contextual clues**: Tweets often contain slang, emojis, URLs, and mentions that, while considered 'noise' in traditional NLP, might carry significant sentiment information within the Twitter domain. BERT, being a large pre-trained language model, might be capable of understanding and extracting meaning from these elements better than simpler models.\n",
        "    *   **Over-cleaning**: Some cleaning steps (e.g., aggressive slang normalization, over-simplification of elongated words) might have removed nuances or specific stylistic elements crucial for sentiment detection in informal text like tweets.\n",
        "    *   **NLTK's `stopwords` interference**: The `synonym_replacement` function used `stopwords.words('english')` without explicitly importing `stopwords`. This could have led to an error or an empty list for stopwords, potentially affecting the augmentation strategy by allowing common words to be replaced when they shouldn't be.\n",
        "\n",
        "3.  **Model C (Augmented Text)**: This model, which used text augmented via synonym replacement, random deletion, and random swapping on top of the cleaned text, performed the worst among the three. Its accuracy was approximately 36.03% and F1-score around 33.03%. This significant drop in performance suggests that the augmentation techniques, as applied, were detrimental. Potential reasons for this degradation include:\n",
        "    *   **Introduction of noise/semantic shift**: Synonym replacement, especially in a nuanced domain like sentiment, can easily alter the original meaning or sentiment polarity of a sentence if not done carefully. Random deletion and swapping can disrupt sentence structure and grammatical coherence, making the text less natural and harder for BERT to process.\n",
        "    *   **Lack of domain-specific augmentation**: Generic augmentation techniques might not be suitable for short, informal texts like tweets, where even minor changes can drastically alter interpretation.\n",
        "    *   **Augmentation quantity/quality**: The degree of augmentation (e.g., `n=1` for replacement/swap, `p=0.1` for deletion) might have been too aggressive or not strategic enough. It's possible that the augmented samples became 'unnatural' and pulled the model away from learning the true sentiment patterns.\n",
        "\n",
        "### Conclusion:\n",
        "\n",
        "The experimental results reveal that for this specific tweet sentiment classification task using `bert-base-uncased`, applying our chosen text cleaning and augmentation strategies did **not** lead to performance improvements. In fact, both cleaning and augmentation resulted in a decrease in metrics compared to using the raw text.\n",
        "\n",
        "This finding addresses the research gap by demonstrating that, contrary to common assumptions, extensive preprocessing or generic data augmentation might not always be beneficial for BERT models, especially when dealing with informal, context-rich data like tweets. BERT's inherent robustness and ability to handle linguistic variations might mean that it can often learn effectively from raw data, and over-processing could remove valuable information. The research highlights the importance of domain-specific and carefully tailored preprocessing and augmentation techniques when working with powerful pre-trained models like BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0b9fc13"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the entire process, including the findings from the BERT models trained on raw, cleaned, and augmented text, and reiterate how the research gap has been addressed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec85e4d0"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "*   **Which preprocessing technique (if any) led to the most significant improvements?**\n",
        "    None of the applied preprocessing techniques (cleaning or augmentation) led to improvements. In fact, training BERT on the raw text (Model A) yielded the best performance.\n",
        "*   **Why might BERT's performance not have improved with cleaned text?**\n",
        "    BERT's performance might not have improved with cleaned text because the cleaning process could have inadvertently removed valuable contextual cues (like slang, emojis, or URLs) that BERT, as a robust pre-trained language model, can leverage for sentiment detection in informal text like tweets. Over-cleaning or an overly aggressive cleaning strategy might have stripped away nuances crucial for the task.\n",
        "*   **How has the research gap been addressed?**\n",
        "    The research gap, which likely explored the impact of different text preprocessing and augmentation strategies on BERT's performance for sentiment classification, has been addressed by demonstrating that, for this specific task and dataset, neither the chosen cleaning nor augmentation strategies improved performance. Instead, they led to a degradation compared to using raw text, challenging the assumption that more preprocessing or generic augmentation is always beneficial for powerful pre-trained models like BERT on informal data.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Model A (Raw Text)** achieved the highest performance across all evaluation metrics, with an accuracy of 0.394750 and an F1-score of 0.372071.\n",
        "*   **Model B (Cleaned Text)** showed a slight degradation in performance compared to the raw text model, with an accuracy of 0.386125 and an F1-score of 0.362607.\n",
        "*   **Model C (Augmented Text)** exhibited the lowest performance, achieving an accuracy of 0.360250 and an F1-score of 0.330328, indicating that the augmentation techniques were detrimental in this context.\n",
        "*   The results suggest that for this tweet sentiment classification task, BERT performed best with raw, unprocessed text, implying that the cleaning and augmentation strategies used might have removed valuable information or introduced noise.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   For informal text like tweets, extensive preprocessing or generic data augmentation techniques may not always enhance BERT model performance. Future work should explore domain-specific and less aggressive preprocessing methods, or augmentation techniques tailored to maintain sentiment and context.\n",
        "*   Investigate the specific elements removed during cleaning (e.g., emojis, slang, URLs) to understand their contribution to sentiment detection by BERT. Additionally, experiment with different augmentation methods or parameters to see if performance can be improved without introducing noise or semantic shifts.\n"
      ]
    }
  ]
}